{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ebf1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9966190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82da8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERS\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "keep_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5965ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'freq'\n",
    "\n",
    "if data_type == 'freq':\n",
    "    data_dir = '/project/r/rbond/jorlo/datasets/act_freq_stamps/'\n",
    "\n",
    "    with np.load(data_dir + 'all_clusters.npz') as data:\n",
    "        pos_im = data['arr_0']\n",
    "    with np.load(data_dir + 'randoms.npz') as data:\n",
    "        neg_im = data['arr_0']    \n",
    "\n",
    "    nchan = 3\n",
    "        \n",
    "if data_type == 'ilc':\n",
    "\n",
    "    data_dir = '/project/r/rbond/jorlo/datasets/act_y_stamps/'\n",
    "\n",
    "    with np.load(data_dir + 'ilc_all_clusters.npz') as data:\n",
    "        pos_im = data['arr_0']\n",
    "    with np.load(data_dir + 'ilc_randoms.npz') as data:\n",
    "        neg_im = data['arr_0']  \n",
    "        \n",
    "    pos_im = np.expand_dims(pos_im, axis=-1)\n",
    "    neg_im = np.expand_dims(neg_im, axis=-1)\n",
    "    \n",
    "    nchan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25d2c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 41, 41, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa6faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = min(pos_im.shape[0], neg_im.shape[0])\n",
    "train_size = int(0.7 * tot)\n",
    "val_size = int(0.15 * tot)\n",
    "test_size = int(0.15 * tot)\n",
    "\n",
    "train_pos = pos_im[:train_size]\n",
    "val_pos = pos_im[train_size:train_size + val_size]\n",
    "test_pos = pos_im[train_size + val_size:]\n",
    "\n",
    "train_neg = neg_im[:train_size]\n",
    "val_neg = neg_im[train_size:train_size + val_size]\n",
    "test_neg = neg_im[train_size + val_size:]\n",
    "\n",
    "input_shape = train_pos.shape[1:]\n",
    "\n",
    "train_images = np.concatenate((train_pos,train_neg))\n",
    "val_images = np.concatenate((val_pos,val_neg))\n",
    "test_images = np.concatenate((test_pos,test_neg))\n",
    "\n",
    "train_labels = np.array(train_pos.shape[0]*[int(1)] + train_neg.shape[0]*[int(0)])\n",
    "val_labels = np.array(val_pos.shape[0]*[int(1)] + val_neg.shape[0]*[int(0)])\n",
    "test_labels = np.array(test_pos.shape[0]*[int(1)] + test_neg.shape[0]*[int(0)])\n",
    "\n",
    "train_images = train_images.transpose(0,3,1,2)\n",
    "val_images = val_images.transpose(0,3,1,2)\n",
    "test_images = test_images.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228a539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360, width_shift_range=4,\n",
    "#height_shift_range=4,zoom_range=0.3)\n",
    "\n",
    "augment = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(360),\n",
    "    torchvision.transforms.RandomHorizontalFlip([0.5]),\n",
    "    torchvision.transforms.RandomVerticalFlip([0.5]),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673152a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.Tensor(train_images)\n",
    "val_images = torch.Tensor(val_images)\n",
    "test_images = torch.Tensor(test_images)\n",
    "\n",
    "train_labels = torch.Tensor(train_labels).type(torch.LongTensor)\n",
    "val_labels = torch.Tensor(val_labels).type(torch.LongTensor)\n",
    "test_labels = torch.Tensor(test_labels).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "val_dataset = TensorDataset(val_images, val_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbcbf87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 41, 41])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6469b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6b63e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffdc0fc0ac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2,0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "017bbf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /home/r/rbond/jorlo/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cae0cd2a154f4a8ddfe4c570893a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "#model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "#model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "model = torchvision.models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "\n",
    "model.fc = nn.Linear(512, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b8eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb0d48a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.153219  [    0/ 5872]\n",
      "loss: 0.293469  [  640/ 5872]\n",
      "loss: 0.274122  [ 1280/ 5872]\n",
      "loss: 0.270329  [ 1920/ 5872]\n",
      "loss: 0.231969  [ 2560/ 5872]\n",
      "loss: 0.273331  [ 3200/ 5872]\n",
      "loss: 0.282823  [ 3840/ 5872]\n",
      "loss: 0.150837  [ 4480/ 5872]\n",
      "loss: 0.213283  [ 5120/ 5872]\n",
      "loss: 0.276281  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.301145 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.114891  [    0/ 5872]\n",
      "loss: 0.195905  [  640/ 5872]\n",
      "loss: 0.299769  [ 1280/ 5872]\n",
      "loss: 0.160627  [ 1920/ 5872]\n",
      "loss: 0.165365  [ 2560/ 5872]\n",
      "loss: 0.098677  [ 3200/ 5872]\n",
      "loss: 0.192066  [ 3840/ 5872]\n",
      "loss: 0.169068  [ 4480/ 5872]\n",
      "loss: 0.158775  [ 5120/ 5872]\n",
      "loss: 0.135874  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.345555 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.227668  [    0/ 5872]\n",
      "loss: 0.227809  [  640/ 5872]\n",
      "loss: 0.252872  [ 1280/ 5872]\n",
      "loss: 0.147044  [ 1920/ 5872]\n",
      "loss: 0.241670  [ 2560/ 5872]\n",
      "loss: 0.152915  [ 3200/ 5872]\n",
      "loss: 0.173360  [ 3840/ 5872]\n",
      "loss: 0.181890  [ 4480/ 5872]\n",
      "loss: 0.175005  [ 5120/ 5872]\n",
      "loss: 0.260458  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.280367 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.202040  [    0/ 5872]\n",
      "loss: 0.202685  [  640/ 5872]\n",
      "loss: 0.148835  [ 1280/ 5872]\n",
      "loss: 0.212828  [ 1920/ 5872]\n",
      "loss: 0.106099  [ 2560/ 5872]\n",
      "loss: 0.145739  [ 3200/ 5872]\n",
      "loss: 0.158014  [ 3840/ 5872]\n",
      "loss: 0.171807  [ 4480/ 5872]\n",
      "loss: 0.200901  [ 5120/ 5872]\n",
      "loss: 0.112194  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.255567 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.154160  [    0/ 5872]\n",
      "loss: 0.145464  [  640/ 5872]\n",
      "loss: 0.112623  [ 1280/ 5872]\n",
      "loss: 0.117650  [ 1920/ 5872]\n",
      "loss: 0.164805  [ 2560/ 5872]\n",
      "loss: 0.194470  [ 3200/ 5872]\n",
      "loss: 0.117421  [ 3840/ 5872]\n",
      "loss: 0.100714  [ 4480/ 5872]\n",
      "loss: 0.200389  [ 5120/ 5872]\n",
      "loss: 0.135072  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.249260 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.144408  [    0/ 5872]\n",
      "loss: 0.118377  [  640/ 5872]\n",
      "loss: 0.192089  [ 1280/ 5872]\n",
      "loss: 0.152092  [ 1920/ 5872]\n",
      "loss: 0.106435  [ 2560/ 5872]\n",
      "loss: 0.152980  [ 3200/ 5872]\n",
      "loss: 0.149501  [ 3840/ 5872]\n",
      "loss: 0.156554  [ 4480/ 5872]\n",
      "loss: 0.160462  [ 5120/ 5872]\n",
      "loss: 0.102560  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.255146 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.120838  [    0/ 5872]\n",
      "loss: 0.149420  [  640/ 5872]\n",
      "loss: 0.185113  [ 1280/ 5872]\n",
      "loss: 0.131411  [ 1920/ 5872]\n",
      "loss: 0.205231  [ 2560/ 5872]\n",
      "loss: 0.237926  [ 3200/ 5872]\n",
      "loss: 0.143093  [ 3840/ 5872]\n",
      "loss: 0.085642  [ 4480/ 5872]\n",
      "loss: 0.098659  [ 5120/ 5872]\n",
      "loss: 0.102284  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.242902 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.213123  [    0/ 5872]\n",
      "loss: 0.099316  [  640/ 5872]\n",
      "loss: 0.146902  [ 1280/ 5872]\n",
      "loss: 0.206466  [ 1920/ 5872]\n",
      "loss: 0.217895  [ 2560/ 5872]\n",
      "loss: 0.100829  [ 3200/ 5872]\n",
      "loss: 0.095421  [ 3840/ 5872]\n",
      "loss: 0.201319  [ 4480/ 5872]\n",
      "loss: 0.113866  [ 5120/ 5872]\n",
      "loss: 0.134077  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.236989 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.163822  [    0/ 5872]\n",
      "loss: 0.088739  [  640/ 5872]\n",
      "loss: 0.105515  [ 1280/ 5872]\n",
      "loss: 0.145489  [ 1920/ 5872]\n",
      "loss: 0.201739  [ 2560/ 5872]\n",
      "loss: 0.164747  [ 3200/ 5872]\n",
      "loss: 0.237992  [ 3840/ 5872]\n",
      "loss: 0.216726  [ 4480/ 5872]\n",
      "loss: 0.074527  [ 5120/ 5872]\n",
      "loss: 0.194599  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.225751 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.085179  [    0/ 5872]\n",
      "loss: 0.172149  [  640/ 5872]\n",
      "loss: 0.110477  [ 1280/ 5872]\n",
      "loss: 0.066479  [ 1920/ 5872]\n",
      "loss: 0.164229  [ 2560/ 5872]\n",
      "loss: 0.115363  [ 3200/ 5872]\n",
      "loss: 0.260145  [ 3840/ 5872]\n",
      "loss: 0.201518  [ 4480/ 5872]\n",
      "loss: 0.208847  [ 5120/ 5872]\n",
      "loss: 0.077787  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.211888 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "177e509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.297247 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bd57975",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/project/r/rbond/jorlo/ml-clusters/models/torch-act/act-mobilenet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34f35acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_model = torchvision.models.mobilenet_v2()\n",
    "backbone_model.fc = nn.Linear(512, 2)\n",
    "backbone_model.load_state_dict(torch.load(\"/project/r/rbond/jorlo/ml-clusters/models/torch-act/act-mobilenet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379878cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb4d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3037a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(nchan, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class test_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(test_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(nchan, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256, 64)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class cifar_test_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(cifar_test_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256, 64)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = test_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a5dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b85de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940c1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e4b6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.693437  [    0/ 4862]\n",
      "loss: 0.692682  [  640/ 4862]\n",
      "loss: 0.688887  [ 1280/ 4862]\n",
      "loss: 0.692684  [ 1920/ 4862]\n",
      "loss: 0.693431  [ 2560/ 4862]\n",
      "loss: 0.691977  [ 3200/ 4862]\n",
      "loss: 0.694814  [ 3840/ 4862]\n",
      "loss: 0.695524  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693517 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.690546  [    0/ 4862]\n",
      "loss: 0.694796  [  640/ 4862]\n",
      "loss: 0.691999  [ 1280/ 4862]\n",
      "loss: 0.694794  [ 1920/ 4862]\n",
      "loss: 0.694095  [ 2560/ 4862]\n",
      "loss: 0.696863  [ 3200/ 4862]\n",
      "loss: 0.693384  [ 3840/ 4862]\n",
      "loss: 0.691324  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693590 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.695430  [    0/ 4862]\n",
      "loss: 0.692708  [  640/ 4862]\n",
      "loss: 0.694021  [ 1280/ 4862]\n",
      "loss: 0.692061  [ 1920/ 4862]\n",
      "loss: 0.690791  [ 2560/ 4862]\n",
      "loss: 0.696526  [ 3200/ 4862]\n",
      "loss: 0.694622  [ 3840/ 4862]\n",
      "loss: 0.692715  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693266 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.695312  [    0/ 4862]\n",
      "loss: 0.692062  [  640/ 4862]\n",
      "loss: 0.695987  [ 1280/ 4862]\n",
      "loss: 0.691406  [ 1920/ 4862]\n",
      "loss: 0.696619  [ 2560/ 4862]\n",
      "loss: 0.694607  [ 3200/ 4862]\n",
      "loss: 0.692720  [ 3840/ 4862]\n",
      "loss: 0.695845  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693529 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.695816  [    0/ 4862]\n",
      "loss: 0.690271  [  640/ 4862]\n",
      "loss: 0.695149  [ 1280/ 4862]\n",
      "loss: 0.695730  [ 1920/ 4862]\n",
      "loss: 0.692731  [ 2560/ 4862]\n",
      "loss: 0.694524  [ 3200/ 4862]\n",
      "loss: 0.695109  [ 3840/ 4862]\n",
      "loss: 0.693329  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693236 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49479b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0])\n",
      "[1,    10] loss: 0.003\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
      "[1,    20] loss: 0.003\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "[1,    30] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1])\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
      "[1,    50] loss: 0.003\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "[1,    60] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0])\n",
      "[1,    70] loss: 0.003\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "947140da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693157 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(val_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddae3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab04d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fba999c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.202\n",
      "[1,  4000] loss: 1.839\n",
      "[1,  6000] loss: 1.657\n",
      "[1,  8000] loss: 1.554\n",
      "[1, 10000] loss: 1.480\n",
      "[1, 12000] loss: 1.389\n",
      "[2,  2000] loss: 1.306\n",
      "[2,  4000] loss: 1.257\n",
      "[2,  6000] loss: 1.223\n",
      "[2,  8000] loss: 1.173\n",
      "[2, 10000] loss: 1.148\n",
      "[2, 12000] loss: 1.107\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.060096  [    0/50000]\n",
      "loss: 0.890363  [  400/50000]\n",
      "loss: 0.372836  [  800/50000]\n",
      "loss: 1.821747  [ 1200/50000]\n",
      "loss: 0.707152  [ 1600/50000]\n",
      "loss: 0.345539  [ 2000/50000]\n",
      "loss: 0.877902  [ 2400/50000]\n",
      "loss: 1.524981  [ 2800/50000]\n",
      "loss: 2.065835  [ 3200/50000]\n",
      "loss: 0.595890  [ 3600/50000]\n",
      "loss: 1.007974  [ 4000/50000]\n",
      "loss: 1.117746  [ 4400/50000]\n",
      "loss: 0.597372  [ 4800/50000]\n",
      "loss: 0.854401  [ 5200/50000]\n",
      "loss: 1.041796  [ 5600/50000]\n",
      "loss: 1.052626  [ 6000/50000]\n",
      "loss: 1.214143  [ 6400/50000]\n",
      "loss: 1.106204  [ 6800/50000]\n",
      "loss: 0.805889  [ 7200/50000]\n",
      "loss: 0.478496  [ 7600/50000]\n",
      "loss: 0.453088  [ 8000/50000]\n",
      "loss: 0.777674  [ 8400/50000]\n",
      "loss: 0.684724  [ 8800/50000]\n",
      "loss: 1.556073  [ 9200/50000]\n",
      "loss: 0.855956  [ 9600/50000]\n",
      "loss: 1.304052  [10000/50000]\n",
      "loss: 0.975991  [10400/50000]\n",
      "loss: 1.312486  [10800/50000]\n",
      "loss: 0.939122  [11200/50000]\n",
      "loss: 1.570962  [11600/50000]\n",
      "loss: 1.059263  [12000/50000]\n",
      "loss: 0.603696  [12400/50000]\n",
      "loss: 1.262460  [12800/50000]\n",
      "loss: 0.899003  [13200/50000]\n",
      "loss: 0.516347  [13600/50000]\n",
      "loss: 1.412817  [14000/50000]\n",
      "loss: 1.940828  [14400/50000]\n",
      "loss: 1.421291  [14800/50000]\n",
      "loss: 1.527958  [15200/50000]\n",
      "loss: 0.660640  [15600/50000]\n",
      "loss: 2.087256  [16000/50000]\n",
      "loss: 1.992364  [16400/50000]\n",
      "loss: 0.742845  [16800/50000]\n",
      "loss: 0.919370  [17200/50000]\n",
      "loss: 2.403116  [17600/50000]\n",
      "loss: 0.861498  [18000/50000]\n",
      "loss: 0.633578  [18400/50000]\n",
      "loss: 0.306112  [18800/50000]\n",
      "loss: 0.616085  [19200/50000]\n",
      "loss: 1.428372  [19600/50000]\n",
      "loss: 1.214573  [20000/50000]\n",
      "loss: 0.237692  [20400/50000]\n",
      "loss: 0.888335  [20800/50000]\n",
      "loss: 1.127685  [21200/50000]\n",
      "loss: 1.894028  [21600/50000]\n",
      "loss: 1.653085  [22000/50000]\n",
      "loss: 0.887104  [22400/50000]\n",
      "loss: 0.768280  [22800/50000]\n",
      "loss: 1.276955  [23200/50000]\n",
      "loss: 0.724101  [23600/50000]\n",
      "loss: 1.389786  [24000/50000]\n",
      "loss: 1.412832  [24400/50000]\n",
      "loss: 0.697471  [24800/50000]\n",
      "loss: 1.534279  [25200/50000]\n",
      "loss: 0.221640  [25600/50000]\n",
      "loss: 0.670590  [26000/50000]\n",
      "loss: 2.082668  [26400/50000]\n",
      "loss: 0.617315  [26800/50000]\n",
      "loss: 0.219669  [27200/50000]\n",
      "loss: 1.576400  [27600/50000]\n",
      "loss: 0.521071  [28000/50000]\n",
      "loss: 0.667109  [28400/50000]\n",
      "loss: 0.446861  [28800/50000]\n",
      "loss: 1.891521  [29200/50000]\n",
      "loss: 0.504127  [29600/50000]\n",
      "loss: 0.900785  [30000/50000]\n",
      "loss: 1.059539  [30400/50000]\n",
      "loss: 1.090192  [30800/50000]\n",
      "loss: 0.438544  [31200/50000]\n",
      "loss: 0.929783  [31600/50000]\n",
      "loss: 1.704021  [32000/50000]\n",
      "loss: 1.206818  [32400/50000]\n",
      "loss: 0.657587  [32800/50000]\n",
      "loss: 0.345679  [33200/50000]\n",
      "loss: 1.015960  [33600/50000]\n",
      "loss: 1.343335  [34000/50000]\n",
      "loss: 0.347090  [34400/50000]\n",
      "loss: 0.932786  [34800/50000]\n",
      "loss: 0.758853  [35200/50000]\n",
      "loss: 0.915432  [35600/50000]\n",
      "loss: 0.995270  [36000/50000]\n",
      "loss: 0.204249  [36400/50000]\n",
      "loss: 0.415024  [36800/50000]\n",
      "loss: 0.493138  [37200/50000]\n",
      "loss: 0.420066  [37600/50000]\n",
      "loss: 1.280315  [38000/50000]\n",
      "loss: 0.264580  [38400/50000]\n",
      "loss: 1.276514  [38800/50000]\n",
      "loss: 1.482562  [39200/50000]\n",
      "loss: 0.770859  [39600/50000]\n",
      "loss: 2.079191  [40000/50000]\n",
      "loss: 1.281586  [40400/50000]\n",
      "loss: 0.515493  [40800/50000]\n",
      "loss: 0.845626  [41200/50000]\n",
      "loss: 0.738795  [41600/50000]\n",
      "loss: 0.445399  [42000/50000]\n",
      "loss: 1.413969  [42400/50000]\n",
      "loss: 1.336969  [42800/50000]\n",
      "loss: 0.504164  [43200/50000]\n",
      "loss: 0.654976  [43600/50000]\n",
      "loss: 0.782981  [44000/50000]\n",
      "loss: 0.397871  [44400/50000]\n",
      "loss: 1.796160  [44800/50000]\n",
      "loss: 1.590147  [45200/50000]\n",
      "loss: 0.364167  [45600/50000]\n",
      "loss: 0.896703  [46000/50000]\n",
      "loss: 1.035134  [46400/50000]\n",
      "loss: 0.276762  [46800/50000]\n",
      "loss: 0.595292  [47200/50000]\n",
      "loss: 0.572970  [47600/50000]\n",
      "loss: 0.073754  [48000/50000]\n",
      "loss: 0.448753  [48400/50000]\n",
      "loss: 0.465436  [48800/50000]\n",
      "loss: 0.205332  [49200/50000]\n",
      "loss: 1.312722  [49600/50000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.639621  [    0/50000]\n",
      "loss: 1.653802  [  400/50000]\n",
      "loss: 0.292712  [  800/50000]\n",
      "loss: 0.695848  [ 1200/50000]\n",
      "loss: 0.864940  [ 1600/50000]\n",
      "loss: 1.086525  [ 2000/50000]\n",
      "loss: 0.244835  [ 2400/50000]\n",
      "loss: 0.362542  [ 2800/50000]\n",
      "loss: 0.355307  [ 3200/50000]\n",
      "loss: 1.828213  [ 3600/50000]\n",
      "loss: 0.367143  [ 4000/50000]\n",
      "loss: 1.277882  [ 4400/50000]\n",
      "loss: 0.404677  [ 4800/50000]\n",
      "loss: 1.039233  [ 5200/50000]\n",
      "loss: 0.240120  [ 5600/50000]\n",
      "loss: 0.288508  [ 6000/50000]\n",
      "loss: 1.079822  [ 6400/50000]\n",
      "loss: 0.691280  [ 6800/50000]\n",
      "loss: 0.616539  [ 7200/50000]\n",
      "loss: 0.250594  [ 7600/50000]\n",
      "loss: 0.478822  [ 8000/50000]\n",
      "loss: 1.108712  [ 8400/50000]\n",
      "loss: 0.735408  [ 8800/50000]\n",
      "loss: 1.227458  [ 9200/50000]\n",
      "loss: 0.875349  [ 9600/50000]\n",
      "loss: 0.750414  [10000/50000]\n",
      "loss: 0.579952  [10400/50000]\n",
      "loss: 0.667180  [10800/50000]\n",
      "loss: 0.434435  [11200/50000]\n",
      "loss: 0.222996  [11600/50000]\n",
      "loss: 0.785771  [12000/50000]\n",
      "loss: 1.845934  [12400/50000]\n",
      "loss: 0.322084  [12800/50000]\n",
      "loss: 0.806117  [13200/50000]\n",
      "loss: 0.476806  [13600/50000]\n",
      "loss: 0.948234  [14000/50000]\n",
      "loss: 1.287097  [14400/50000]\n",
      "loss: 0.955032  [14800/50000]\n",
      "loss: 1.221172  [15200/50000]\n",
      "loss: 0.647941  [15600/50000]\n",
      "loss: 1.866461  [16000/50000]\n",
      "loss: 0.596470  [16400/50000]\n",
      "loss: 0.736356  [16800/50000]\n",
      "loss: 0.987067  [17200/50000]\n",
      "loss: 1.188918  [17600/50000]\n",
      "loss: 1.121629  [18000/50000]\n",
      "loss: 0.608543  [18400/50000]\n",
      "loss: 0.826440  [18800/50000]\n",
      "loss: 0.224803  [19200/50000]\n",
      "loss: 1.689422  [19600/50000]\n",
      "loss: 0.592396  [20000/50000]\n",
      "loss: 0.991186  [20400/50000]\n",
      "loss: 2.725237  [20800/50000]\n",
      "loss: 1.783676  [21200/50000]\n",
      "loss: 0.919037  [21600/50000]\n",
      "loss: 0.479510  [22000/50000]\n",
      "loss: 2.341299  [22400/50000]\n",
      "loss: 0.858123  [22800/50000]\n",
      "loss: 0.478736  [23200/50000]\n",
      "loss: 0.325498  [23600/50000]\n",
      "loss: 0.964267  [24000/50000]\n",
      "loss: 0.981799  [24400/50000]\n",
      "loss: 0.135917  [24800/50000]\n",
      "loss: 0.860336  [25200/50000]\n",
      "loss: 1.013093  [25600/50000]\n",
      "loss: 0.680560  [26000/50000]\n",
      "loss: 0.200244  [26400/50000]\n",
      "loss: 0.774907  [26800/50000]\n",
      "loss: 1.491934  [27200/50000]\n",
      "loss: 0.056649  [27600/50000]\n",
      "loss: 0.515200  [28000/50000]\n",
      "loss: 1.231576  [28400/50000]\n",
      "loss: 0.140577  [28800/50000]\n",
      "loss: 0.326717  [29200/50000]\n",
      "loss: 1.532465  [29600/50000]\n",
      "loss: 0.731401  [30000/50000]\n",
      "loss: 0.604404  [30400/50000]\n",
      "loss: 0.812461  [30800/50000]\n",
      "loss: 0.689520  [31200/50000]\n",
      "loss: 0.852476  [31600/50000]\n",
      "loss: 0.542539  [32000/50000]\n",
      "loss: 0.864933  [32400/50000]\n",
      "loss: 1.742018  [32800/50000]\n",
      "loss: 0.607229  [33200/50000]\n",
      "loss: 1.449111  [33600/50000]\n",
      "loss: 1.386970  [34000/50000]\n",
      "loss: 0.857375  [34400/50000]\n",
      "loss: 0.867152  [34800/50000]\n",
      "loss: 1.795165  [35200/50000]\n",
      "loss: 0.335545  [35600/50000]\n",
      "loss: 0.849488  [36000/50000]\n",
      "loss: 0.586552  [36400/50000]\n",
      "loss: 0.363186  [36800/50000]\n",
      "loss: 1.388242  [37200/50000]\n",
      "loss: 0.587786  [37600/50000]\n",
      "loss: 0.626836  [38000/50000]\n",
      "loss: 0.426292  [38400/50000]\n",
      "loss: 1.404154  [38800/50000]\n",
      "loss: 1.268189  [39200/50000]\n",
      "loss: 0.529208  [39600/50000]\n",
      "loss: 0.831767  [40000/50000]\n",
      "loss: 0.620528  [40400/50000]\n",
      "loss: 0.456411  [40800/50000]\n",
      "loss: 0.862475  [41200/50000]\n",
      "loss: 1.396451  [41600/50000]\n",
      "loss: 1.297489  [42000/50000]\n",
      "loss: 0.222226  [42400/50000]\n",
      "loss: 0.772526  [42800/50000]\n",
      "loss: 0.380015  [43200/50000]\n",
      "loss: 0.525589  [43600/50000]\n",
      "loss: 1.086556  [44000/50000]\n",
      "loss: 0.762763  [44400/50000]\n",
      "loss: 0.389924  [44800/50000]\n",
      "loss: 1.205146  [45200/50000]\n",
      "loss: 0.751991  [45600/50000]\n",
      "loss: 1.432924  [46000/50000]\n",
      "loss: 0.451831  [46400/50000]\n",
      "loss: 1.337262  [46800/50000]\n",
      "loss: 0.885977  [47200/50000]\n",
      "loss: 1.849783  [47600/50000]\n",
      "loss: 0.634227  [48000/50000]\n",
      "loss: 0.344398  [48400/50000]\n",
      "loss: 0.358285  [48800/50000]\n",
      "loss: 1.302626  [49200/50000]\n",
      "loss: 0.863636  [49600/50000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.202002  [    0/50000]\n",
      "loss: 0.995692  [  400/50000]\n",
      "loss: 0.054721  [  800/50000]\n",
      "loss: 1.228471  [ 1200/50000]\n",
      "loss: 0.690716  [ 1600/50000]\n",
      "loss: 0.924596  [ 2000/50000]\n",
      "loss: 0.739889  [ 2400/50000]\n",
      "loss: 0.347516  [ 2800/50000]\n",
      "loss: 1.594353  [ 3200/50000]\n",
      "loss: 0.499001  [ 3600/50000]\n",
      "loss: 0.414310  [ 4000/50000]\n",
      "loss: 1.066976  [ 4400/50000]\n",
      "loss: 0.894724  [ 4800/50000]\n",
      "loss: 0.425009  [ 5200/50000]\n",
      "loss: 0.261705  [ 5600/50000]\n",
      "loss: 1.619232  [ 6000/50000]\n",
      "loss: 0.685091  [ 6400/50000]\n",
      "loss: 0.631607  [ 6800/50000]\n",
      "loss: 1.542419  [ 7200/50000]\n",
      "loss: 0.853632  [ 7600/50000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.742525  [ 8000/50000]\n",
      "loss: 0.778277  [ 8400/50000]\n",
      "loss: 1.118055  [ 8800/50000]\n",
      "loss: 0.483934  [ 9200/50000]\n",
      "loss: 1.168017  [ 9600/50000]\n",
      "loss: 3.126446  [10000/50000]\n",
      "loss: 0.204966  [10400/50000]\n",
      "loss: 0.672307  [10800/50000]\n",
      "loss: 0.938400  [11200/50000]\n",
      "loss: 1.151416  [11600/50000]\n",
      "loss: 0.302296  [12000/50000]\n",
      "loss: 1.558384  [12400/50000]\n",
      "loss: 1.100916  [12800/50000]\n",
      "loss: 0.109435  [13200/50000]\n",
      "loss: 1.966909  [13600/50000]\n",
      "loss: 0.198178  [14000/50000]\n",
      "loss: 3.015626  [14400/50000]\n",
      "loss: 0.780849  [14800/50000]\n",
      "loss: 1.495462  [15200/50000]\n",
      "loss: 0.285534  [15600/50000]\n",
      "loss: 0.262317  [16000/50000]\n",
      "loss: 1.562996  [16400/50000]\n",
      "loss: 2.144889  [16800/50000]\n",
      "loss: 0.275759  [17200/50000]\n",
      "loss: 0.508386  [17600/50000]\n",
      "loss: 2.900773  [18000/50000]\n",
      "loss: 0.261640  [18400/50000]\n",
      "loss: 1.003810  [18800/50000]\n",
      "loss: 0.680074  [19200/50000]\n",
      "loss: 0.399111  [19600/50000]\n",
      "loss: 0.417976  [20000/50000]\n",
      "loss: 1.109479  [20400/50000]\n",
      "loss: 1.602119  [20800/50000]\n",
      "loss: 0.740902  [21200/50000]\n",
      "loss: 0.912175  [21600/50000]\n",
      "loss: 0.702477  [22000/50000]\n",
      "loss: 1.340326  [22400/50000]\n",
      "loss: 0.292778  [22800/50000]\n",
      "loss: 3.001721  [23200/50000]\n",
      "loss: 0.282721  [23600/50000]\n",
      "loss: 0.429418  [24000/50000]\n",
      "loss: 1.204721  [24400/50000]\n",
      "loss: 1.009758  [24800/50000]\n",
      "loss: 0.989984  [25200/50000]\n",
      "loss: 0.544792  [25600/50000]\n",
      "loss: 0.138613  [26000/50000]\n",
      "loss: 0.727053  [26400/50000]\n",
      "loss: 1.291738  [26800/50000]\n",
      "loss: 0.380883  [27200/50000]\n",
      "loss: 0.737675  [27600/50000]\n",
      "loss: 1.668164  [28000/50000]\n",
      "loss: 0.424108  [28400/50000]\n",
      "loss: 1.128641  [28800/50000]\n",
      "loss: 0.448262  [29200/50000]\n",
      "loss: 0.502998  [29600/50000]\n",
      "loss: 1.390533  [30000/50000]\n",
      "loss: 0.461268  [30400/50000]\n",
      "loss: 0.468525  [30800/50000]\n",
      "loss: 0.276306  [31200/50000]\n",
      "loss: 0.202937  [31600/50000]\n",
      "loss: 1.118357  [32000/50000]\n",
      "loss: 0.761776  [32400/50000]\n",
      "loss: 1.906657  [32800/50000]\n",
      "loss: 0.744753  [33200/50000]\n",
      "loss: 0.430453  [33600/50000]\n",
      "loss: 0.125181  [34000/50000]\n",
      "loss: 1.102085  [34400/50000]\n",
      "loss: 3.156640  [34800/50000]\n",
      "loss: 1.313067  [35200/50000]\n",
      "loss: 1.359367  [35600/50000]\n",
      "loss: 1.016252  [36000/50000]\n",
      "loss: 0.646700  [36400/50000]\n",
      "loss: 0.217673  [36800/50000]\n",
      "loss: 0.690380  [37200/50000]\n",
      "loss: 0.968114  [37600/50000]\n",
      "loss: 0.067531  [38000/50000]\n",
      "loss: 0.738000  [38400/50000]\n",
      "loss: 1.576040  [38800/50000]\n",
      "loss: 0.448933  [39200/50000]\n",
      "loss: 0.769586  [39600/50000]\n",
      "loss: 2.070192  [40000/50000]\n",
      "loss: 0.186902  [40400/50000]\n",
      "loss: 1.291891  [40800/50000]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b02cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532f348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1640fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbee108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5b887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca1a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54e5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3343235/3906010888.py:33: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=625, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of CNN/ConvNet Model\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        # Conv -> (?, 28, 28, 32)\n",
    "        # Pool -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        # Conv      ->(?, 14, 14, 64)\n",
    "        # Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        # Conv ->(?, 7, 7, 128)\n",
    "        # Pool ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#instantiate CNN model\n",
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d5944a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.333513  [    0/60000]\n",
      "loss: 2.310068  [ 6400/60000]\n",
      "loss: 2.273524  [12800/60000]\n",
      "loss: 2.255716  [19200/60000]\n",
      "loss: 2.244400  [25600/60000]\n",
      "loss: 2.212022  [32000/60000]\n",
      "loss: 2.213074  [38400/60000]\n",
      "loss: 2.173571  [44800/60000]\n",
      "loss: 2.146094  [51200/60000]\n",
      "loss: 2.090101  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.063510 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.088126  [    0/60000]\n",
      "loss: 2.029327  [ 6400/60000]\n",
      "loss: 1.865700  [12800/60000]\n",
      "loss: 1.799059  [19200/60000]\n",
      "loss: 1.561360  [25600/60000]\n",
      "loss: 1.439963  [32000/60000]\n",
      "loss: 1.300343  [38400/60000]\n",
      "loss: 1.148937  [44800/60000]\n",
      "loss: 1.130939  [51200/60000]\n",
      "loss: 1.039372  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.964817 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.035348  [    0/60000]\n",
      "loss: 1.024850  [ 6400/60000]\n",
      "loss: 0.736442  [12800/60000]\n",
      "loss: 0.960207  [19200/60000]\n",
      "loss: 0.845868  [25600/60000]\n",
      "loss: 0.868031  [32000/60000]\n",
      "loss: 0.871768  [38400/60000]\n",
      "loss: 0.744164  [44800/60000]\n",
      "loss: 0.841591  [51200/60000]\n",
      "loss: 0.886496  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.774923 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.766985  [    0/60000]\n",
      "loss: 0.864394  [ 6400/60000]\n",
      "loss: 0.576703  [12800/60000]\n",
      "loss: 0.865990  [19200/60000]\n",
      "loss: 0.773797  [25600/60000]\n",
      "loss: 0.791727  [32000/60000]\n",
      "loss: 0.804248  [38400/60000]\n",
      "loss: 0.685180  [44800/60000]\n",
      "loss: 0.774078  [51200/60000]\n",
      "loss: 0.833923  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.724752 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.676635  [    0/60000]\n",
      "loss: 0.793786  [ 6400/60000]\n",
      "loss: 0.523416  [12800/60000]\n",
      "loss: 0.812837  [19200/60000]\n",
      "loss: 0.729965  [25600/60000]\n",
      "loss: 0.759640  [32000/60000]\n",
      "loss: 0.761278  [38400/60000]\n",
      "loss: 0.654649  [44800/60000]\n",
      "loss: 0.741718  [51200/60000]\n",
      "loss: 0.792836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.693916 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.622157  [    0/60000]\n",
      "loss: 0.745662  [ 6400/60000]\n",
      "loss: 0.489755  [12800/60000]\n",
      "loss: 0.771136  [19200/60000]\n",
      "loss: 0.704861  [25600/60000]\n",
      "loss: 0.740639  [32000/60000]\n",
      "loss: 0.727107  [38400/60000]\n",
      "loss: 0.631473  [44800/60000]\n",
      "loss: 0.722566  [51200/60000]\n",
      "loss: 0.757392  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.669962 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.581996  [    0/60000]\n",
      "loss: 0.708483  [ 6400/60000]\n",
      "loss: 0.464897  [12800/60000]\n",
      "loss: 0.736457  [19200/60000]\n",
      "loss: 0.686697  [25600/60000]\n",
      "loss: 0.724395  [32000/60000]\n",
      "loss: 0.700341  [38400/60000]\n",
      "loss: 0.615090  [44800/60000]\n",
      "loss: 0.709408  [51200/60000]\n",
      "loss: 0.726727  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.649821 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.549971  [    0/60000]\n",
      "loss: 0.677273  [ 6400/60000]\n",
      "loss: 0.443762  [12800/60000]\n",
      "loss: 0.707362  [19200/60000]\n",
      "loss: 0.670232  [25600/60000]\n",
      "loss: 0.709434  [32000/60000]\n",
      "loss: 0.676416  [38400/60000]\n",
      "loss: 0.600556  [44800/60000]\n",
      "loss: 0.699560  [51200/60000]\n",
      "loss: 0.699143  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.631920 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.523097  [    0/60000]\n",
      "loss: 0.649075  [ 6400/60000]\n",
      "loss: 0.424766  [12800/60000]\n",
      "loss: 0.681190  [19200/60000]\n",
      "loss: 0.654910  [25600/60000]\n",
      "loss: 0.693513  [32000/60000]\n",
      "loss: 0.654135  [38400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e339e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cceed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0dfca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d08af891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "738cc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e5a77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35e2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        print(y)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d84af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-torch",
   "language": "python",
   "name": "ml-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
