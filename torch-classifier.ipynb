{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ebf1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9966190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a4b79-a28f-4521-8b77-2685cbb7173c",
   "metadata": {},
   "source": [
    "Define some so-called Hyper parameters. These are parameters relating to how we train the model and how the model is set up, rather than actually being parameters of the model itself. You don't need to worry a ton about these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82da8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERS\n",
    "\n",
    "learning_rate = 1e-3 #Defines how quickly the model changes its parameters. Too fast and it will \"jump around\"\n",
    "batch_size = 64 #Give the model batch_size images at a time. Done because GPUs only have so much ram\n",
    "epochs = 10 #Number of times to go through fitting\n",
    "keep_prob = 1 #IDK TBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5965ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'freq' #What type of data we are taking in. In this case, it's frequency maps\n",
    "\n",
    "if data_type == 'freq':\n",
    "    #data_dir = '/project/r/rbond/jorlo/datasets/act_freq_stamps/'\n",
    "    data_dir = \"/mnt/welch/USERS/jorlo/ml-clusters/act_freq_stamps/\"\n",
    "    with np.load(data_dir + 'all_clusters_offset.npz') as data:\n",
    "        pos_im = data['arr_0']\n",
    "    with np.load(data_dir + 'randoms.npz') as data:\n",
    "        neg_im = data['arr_0']    \n",
    "\n",
    "    nchan = 3\n",
    "        \n",
    "if data_type == 'ilc':\n",
    "\n",
    "    #data_dir = '/project/r/rbond/jorlo/datasets/act_y_stamps/'\n",
    "    data_dir = \"/mnt/welch/USERS/jorlo/ml-clusters/act_y_stamps/\"\n",
    "    with np.load(data_dir + 'ilc_all_clusters.npz') as data:\n",
    "        pos_im = data['arr_0']\n",
    "    with np.load(data_dir + 'ilc_randoms.npz') as data:\n",
    "        neg_im = data['arr_0']  \n",
    "        \n",
    "    pos_im = np.expand_dims(pos_im, axis=-1)\n",
    "    neg_im = np.expand_dims(neg_im, axis=-1)\n",
    "    \n",
    "    nchan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25d2c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 41, 41, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501395b-ab20-42c4-a525-f0c6fac6bd90",
   "metadata": {},
   "source": [
    "Next we split our data up into a train (70%), validate (15%), and test (15%) subsets. The train data is given to the model for it to learn from. The model will try to learn how to correctly predict the label (i.e., cluster or non-cluster) from the input image. Note that ML methods are prone to \"overfitting\" where they learn what the specific input dataset looks like but can't generalize. At it's most extreme, because there are so many tunable parameters, the model can directly map input images onto their correct labels, with no ability to generalize whatsoever. Image augmentation, discussed below, can help with this, but it's also important to completely separate the data used to train the model from what we validate on. The validation dataset is used to track the progress of our model. We can tweak aspects of our model to improve the fit, using the validation dataset to track our progress. The test data set is effectively our \"blind\" data set. As scientists we are prone to tweaking our analysis methods until the result we expect occurs. This leads to a confirmation bias of sorts. To help mitigate this, we reserve a test data set which we only look at at the very end, once we are confident our model is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa6faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tot = min(pos_im.shape[0], neg_im.shape[0])\n",
    "train_size = int(0.7 * tot)\n",
    "val_size = int(0.15 * tot)\n",
    "test_size = int(0.15 * tot)\n",
    "\n",
    "train_pos = pos_im[:train_size]\n",
    "val_pos = pos_im[train_size:train_size + val_size]\n",
    "test_pos = pos_im[train_size + val_size:]\n",
    "\n",
    "train_neg = neg_im[:train_size]\n",
    "val_neg = neg_im[train_size:train_size + val_size]\n",
    "test_neg = neg_im[train_size + val_size:]\n",
    "\n",
    "input_shape = train_pos.shape[1:]\n",
    "\n",
    "train_images = np.concatenate((train_pos,train_neg))\n",
    "val_images = np.concatenate((val_pos,val_neg))\n",
    "test_images = np.concatenate((test_pos,test_neg))\n",
    "\n",
    "train_labels = np.array(train_pos.shape[0]*[int(1)] + train_neg.shape[0]*[int(0)])\n",
    "val_labels = np.array(val_pos.shape[0]*[int(1)] + val_neg.shape[0]*[int(0)])\n",
    "test_labels = np.array(test_pos.shape[0]*[int(1)] + test_neg.shape[0]*[int(0)])\n",
    "\n",
    "#There's a mismatch between the axis ordering we input and what Torch expects, which is\n",
    "#nimages, nchannels, nx, ny\n",
    "train_images = train_images.transpose(0,3,1,2)\n",
    "val_images = val_images.transpose(0,3,1,2)\n",
    "test_images = test_images.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a61cc1-cf08-410d-b534-aec91432b52f",
   "metadata": {},
   "source": [
    "Next we're going to augment the data by applying some isometric transformations to the images randomly. An image of a cluster rotated 20 deg is still an image of a cluster; image augmentation helps the model generalize both by augmenting the size of the dataset and by stopping it from learning the exact input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228a539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360, width_shift_range=4,\n",
    "#height_shift_range=4,zoom_range=0.3)\n",
    "\n",
    "augment = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(360),\n",
    "    torchvision.transforms.RandomHorizontalFlip([0.5]),\n",
    "    torchvision.transforms.RandomVerticalFlip([0.5]),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673152a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is all just boilerplate to turn our input numpy arrays into\n",
    "#the actual Class (DataLoader) Torch expects.\n",
    "train_images = torch.Tensor(train_images)\n",
    "val_images = torch.Tensor(val_images)\n",
    "test_images = torch.Tensor(test_images)\n",
    "\n",
    "train_labels = torch.Tensor(train_labels).type(torch.LongTensor)\n",
    "val_labels = torch.Tensor(val_labels).type(torch.LongTensor)\n",
    "test_labels = torch.Tensor(test_labels).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "val_dataset = TensorDataset(val_images, val_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbcbf87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image_batch [N, C, H, W]: torch.Size([64, 3, 41, 41])\n",
      "Shape of labels: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#DataLoader is what's called an iterator, basically\n",
    "#every time you call it you get another member drawn \n",
    "#without replacement from the pool.\n",
    "for image_batch, labels in test_dataloader:\n",
    "    print(f\"Shape of image_batch [N, C, H, W]: {image_batch.shape}\")\n",
    "    print(f\"Shape of labels: {labels.shape} {labels.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6469b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don not remember why we have to cast dataloader\n",
    "#to an interable here, it should already be one\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6b63e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2,0,...])\n",
    "print(labels[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57773b0d-91e8-414a-a8fb-ee2b2d6ce391",
   "metadata": {},
   "source": [
    "Next we're going to set up our model. Torch comes preloaded with some very useful models which have already been pretrained. You might think, \"Well, what use is identifying what a car or a horse looks like to us\" but a lot of the low level filters are the same, identifying different types of gradients for example. We'll fine tune (i.e., tweak the weights of) this model to work for us, but loading the pretrained weights will save us time. The architecture we're using is called ResNet, you can read the full details here https://arxiv.org/pdf/1512.03385 BTW this paper has 220 THOUSAND citations. The basic idea is that at each lay of the model, the out put of the layer above is subtracted off, so that the subsequent layer will have to learn new features from the residual (hence the name of the model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017bbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "#model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "#model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "model = torchvision.models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "\n",
    "model.fc = nn.Linear(512, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda3400-171c-4d73-b10e-1b911206e291",
   "metadata": {},
   "source": [
    "Here we write functions which we will use to actually tune the model. The idea is we first load in a sample (X, y = X...). We then call model on the inputs to get a pred = model(X). We then compute what's called the loss on our prediction reltaive to the labels. The loss is a function that computes how far off the prediction is from the ground truth. This is pretty simple for labels but can be more complicated for more complicated predicitions. We then do backpropogation. This is the magic step where we update our model parameters based on the loss. Formally what we do is compute the gradient of the loss with respect to the model parameters, and then step some distance along that gradient. This is somewhat like, although not exactly, Newton's method. Test loop does a very similar thing but it doesn't actually update the model parameters, since of course we are testing the model, not training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b8eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97194f1-098b-44ec-b42e-7c6942f7d8e8",
   "metadata": {},
   "source": [
    "We can now train the model. After even 10 epochs we achieve ~90% accuracy, but we can increase the number of epochs to improve that. One thing to keep in mind is that we will hit diminishing returns as we increase the number of epochs, as well as put ourselves at risk for overfitting, although the augmenter does help with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb0d48a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.165168  [    0/ 5872]\n",
      "loss: 0.232457  [  640/ 5872]\n",
      "loss: 0.150525  [ 1280/ 5872]\n",
      "loss: 0.085614  [ 1920/ 5872]\n",
      "loss: 0.116460  [ 2560/ 5872]\n",
      "loss: 0.140441  [ 3200/ 5872]\n",
      "loss: 0.145660  [ 3840/ 5872]\n",
      "loss: 0.207489  [ 4480/ 5872]\n",
      "loss: 0.158142  [ 5120/ 5872]\n",
      "loss: 0.125715  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.214181 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.160776  [    0/ 5872]\n",
      "loss: 0.107118  [  640/ 5872]\n",
      "loss: 0.054866  [ 1280/ 5872]\n",
      "loss: 0.320117  [ 1920/ 5872]\n",
      "loss: 0.300904  [ 2560/ 5872]\n",
      "loss: 0.076521  [ 3200/ 5872]\n",
      "loss: 0.074331  [ 3840/ 5872]\n",
      "loss: 0.194182  [ 4480/ 5872]\n",
      "loss: 0.107266  [ 5120/ 5872]\n",
      "loss: 0.232741  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.213556 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.152634  [    0/ 5872]\n",
      "loss: 0.082686  [  640/ 5872]\n",
      "loss: 0.082369  [ 1280/ 5872]\n",
      "loss: 0.107628  [ 1920/ 5872]\n",
      "loss: 0.132923  [ 2560/ 5872]\n",
      "loss: 0.144944  [ 3200/ 5872]\n",
      "loss: 0.127563  [ 3840/ 5872]\n",
      "loss: 0.111881  [ 4480/ 5872]\n",
      "loss: 0.105462  [ 5120/ 5872]\n",
      "loss: 0.076092  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.239389 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.114754  [    0/ 5872]\n",
      "loss: 0.144275  [  640/ 5872]\n",
      "loss: 0.154135  [ 1280/ 5872]\n",
      "loss: 0.111725  [ 1920/ 5872]\n",
      "loss: 0.112519  [ 2560/ 5872]\n",
      "loss: 0.119372  [ 3200/ 5872]\n",
      "loss: 0.055443  [ 3840/ 5872]\n",
      "loss: 0.301463  [ 4480/ 5872]\n",
      "loss: 0.134560  [ 5120/ 5872]\n",
      "loss: 0.117539  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.225030 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.105022  [    0/ 5872]\n",
      "loss: 0.065277  [  640/ 5872]\n",
      "loss: 0.132296  [ 1280/ 5872]\n",
      "loss: 0.124404  [ 1920/ 5872]\n",
      "loss: 0.126171  [ 2560/ 5872]\n",
      "loss: 0.081250  [ 3200/ 5872]\n",
      "loss: 0.109478  [ 3840/ 5872]\n",
      "loss: 0.175455  [ 4480/ 5872]\n",
      "loss: 0.146396  [ 5120/ 5872]\n",
      "loss: 0.113860  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.217509 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.079224  [    0/ 5872]\n",
      "loss: 0.150736  [  640/ 5872]\n",
      "loss: 0.068670  [ 1280/ 5872]\n",
      "loss: 0.101682  [ 1920/ 5872]\n",
      "loss: 0.116630  [ 2560/ 5872]\n",
      "loss: 0.060162  [ 3200/ 5872]\n",
      "loss: 0.357246  [ 3840/ 5872]\n",
      "loss: 0.061497  [ 4480/ 5872]\n",
      "loss: 0.144407  [ 5120/ 5872]\n",
      "loss: 0.075743  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.222488 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.121190  [    0/ 5872]\n",
      "loss: 0.105714  [  640/ 5872]\n",
      "loss: 0.073534  [ 1280/ 5872]\n",
      "loss: 0.102012  [ 1920/ 5872]\n",
      "loss: 0.135681  [ 2560/ 5872]\n",
      "loss: 0.080848  [ 3200/ 5872]\n",
      "loss: 0.063884  [ 3840/ 5872]\n",
      "loss: 0.151176  [ 4480/ 5872]\n",
      "loss: 0.106575  [ 5120/ 5872]\n",
      "loss: 0.192698  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.213360 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.048773  [    0/ 5872]\n",
      "loss: 0.075812  [  640/ 5872]\n",
      "loss: 0.082664  [ 1280/ 5872]\n",
      "loss: 0.175364  [ 1920/ 5872]\n",
      "loss: 0.096802  [ 2560/ 5872]\n",
      "loss: 0.079767  [ 3200/ 5872]\n",
      "loss: 0.087759  [ 3840/ 5872]\n",
      "loss: 0.055001  [ 4480/ 5872]\n",
      "loss: 0.080161  [ 5120/ 5872]\n",
      "loss: 0.068608  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.206657 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.123900  [    0/ 5872]\n",
      "loss: 0.169200  [  640/ 5872]\n",
      "loss: 0.077073  [ 1280/ 5872]\n",
      "loss: 0.108137  [ 1920/ 5872]\n",
      "loss: 0.119261  [ 2560/ 5872]\n",
      "loss: 0.060213  [ 3200/ 5872]\n",
      "loss: 0.117184  [ 3840/ 5872]\n",
      "loss: 0.108555  [ 4480/ 5872]\n",
      "loss: 0.086408  [ 5120/ 5872]\n",
      "loss: 0.126589  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.215504 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.127947  [    0/ 5872]\n",
      "loss: 0.073009  [  640/ 5872]\n",
      "loss: 0.118445  [ 1280/ 5872]\n",
      "loss: 0.123134  [ 1920/ 5872]\n",
      "loss: 0.113284  [ 2560/ 5872]\n",
      "loss: 0.118099  [ 3200/ 5872]\n",
      "loss: 0.112557  [ 3840/ 5872]\n",
      "loss: 0.085632  [ 4480/ 5872]\n",
      "loss: 0.084920  [ 5120/ 5872]\n",
      "loss: 0.107614  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.216065 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "177e509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.222486 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8fe11-0451-49e8-ab41-f3cf039aa34c",
   "metadata": {},
   "source": [
    "This code saves the weights for later use then reloads them just to make sure everything worked right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bd57975",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/mnt/welch/USERS/jorlo/ml-clusters/models/torch-act/\"\n",
    "torch.save(model.state_dict(), save_dir + \"act-mobilenet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34f35acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_model = torchvision.models.mobilenet_v2()\n",
    "backbone_model.fc = nn.Linear(512, 2)\n",
    "backbone_model.load_state_dict(torch.load(save_dir + \"act-mobilenet.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbef376",
   "metadata": {},
   "source": [
    "# WISE Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b4559-e3f5-4a08-833c-245c58fac941",
   "metadata": {},
   "source": [
    "This code is doing something very similar to the above code but using WISE images instead of ACT. You can look through this if you'd like, however the code is not set up run on PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "24cacc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_im = []\n",
    "neg_im = []\n",
    "\n",
    "act_catalog = fits.open('/gpfs/fs0/project/r/rbond/jorlo/cluster_catalogs/DR5_cluster-catalog_v1.0b2.fits')\n",
    "zs = np.array(act_catalog[1].data['redshift'])\n",
    "\n",
    "z_cut = 0\n",
    "\n",
    "data_dir = '/project/r/rbond/jorlo/datasets/act_centered_wise_stamps/'\n",
    "\n",
    "#I made images centered on ACT and DES cluster locations (positives) as well as random points at least 5' \n",
    "#from a known cluster (negatives). This code just loads those\n",
    "for directory in os.listdir(data_dir+'clusters/'):\n",
    "    j = int(str(directory[-8:-4]).strip('0'))\n",
    "    if zs[j] < z_cut: continue\n",
    "    with np.load(data_dir+'clusters/' + directory) as data:\n",
    "            pos_im.append(data['arr_0'])\n",
    "            \n",
    "for directory in os.listdir(data_dir+'randoms/'):            \n",
    "    with np.load(data_dir+'randoms/' + directory) as data:\n",
    "            neg_im.append(data['arr_0'])\n",
    "pos_im = np.array(pos_im)\n",
    "neg_im = np.array(neg_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "adb3ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#cuts out any maps that have nans in them\n",
    "flags = []\n",
    "for i in range(pos_im.shape[0]):\n",
    "        if np.any(np.isnan(pos_im[i,...])):\n",
    "                flags.append(i)\n",
    "\n",
    "pos_im = np.delete(pos_im, flags, axis = 0)\n",
    "\n",
    "flags = []\n",
    "for i in range(neg_im.shape[0]):\n",
    "        if np.any(np.isnan(neg_im[i,...])):\n",
    "                flags.append(i)\n",
    "\n",
    "neg_im = np.delete(neg_im, flags, axis = 0)\n",
    "\n",
    "neg_im = neg_im[:len(pos_im)]\n",
    "pos_im = pos_im[:len(neg_im)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a7e68425",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_cuts = [500,  500, 2000, 4000]\n",
    "\n",
    "flags = []\n",
    "for j, im in enumerate(pos_im):\n",
    "    for i in range(4):\n",
    "        if np.any(im[...,i] > hard_cuts[i]):\n",
    "            flags.append(j)\n",
    "            break\n",
    "pos_im = np.delete(pos_im, flags, axis = 0)\n",
    "\n",
    "flags = []\n",
    "for j, im in enumerate(neg_im):\n",
    "    for i in range(4):\n",
    "        if np.any(im[...,i] > hard_cuts[i]):\n",
    "            flags.append(j)\n",
    "            break\n",
    "neg_im = np.delete(neg_im, flags, axis = 0)\n",
    "\n",
    "neg_im = neg_im[:len(pos_im)]\n",
    "pos_im = pos_im[:len(neg_im)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5701d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask vvv bright point sources\n",
    "\n",
    "cuts = [100, 100, 99999, 999999]\n",
    "\n",
    "for im in pos_im:\n",
    "    for i in range(4):\n",
    "        im[...,i][im[...,i] >= cuts[i]] = np.random.rand()\n",
    "for im in neg_im:\n",
    "    for i in range(4):\n",
    "        im[...,i][im[...,i] >= cuts[i]] = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "52a4e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = [30, 30, 300, 80]\n",
    "for i in range(4):\n",
    "    pos_im[..., i]/= norms[i]\n",
    "    neg_im[..., i]/= norms[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69b83585",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = 3\n",
    "pos_im = pos_im[...,:bands]\n",
    "neg_im = neg_im[...,:bands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16848e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "733883eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = min(pos_im.shape[0], neg_im.shape[0])\n",
    "train_size = int(0.7 * tot)\n",
    "val_size = int(0.15 * tot)\n",
    "test_size = int(0.15 * tot)\n",
    "\n",
    "train_pos = pos_im[:train_size]\n",
    "val_pos = pos_im[train_size:train_size + val_size]\n",
    "test_pos = pos_im[train_size + val_size:]\n",
    "\n",
    "train_neg = neg_im[:train_size]\n",
    "val_neg = neg_im[train_size:train_size + val_size]\n",
    "test_neg = neg_im[train_size + val_size:]\n",
    "\n",
    "input_shape = train_pos.shape[1:]\n",
    "\n",
    "train_images = np.concatenate((train_pos,train_neg))\n",
    "val_images = np.concatenate((val_pos,val_neg))\n",
    "test_images = np.concatenate((test_pos,test_neg))\n",
    "\n",
    "train_labels = np.array(train_pos.shape[0]*[int(1)] + train_neg.shape[0]*[int(0)])\n",
    "val_labels = np.array(val_pos.shape[0]*[int(1)] + val_neg.shape[0]*[int(0)])\n",
    "test_labels = np.array(test_pos.shape[0]*[int(1)] + test_neg.shape[0]*[int(0)])\n",
    "\n",
    "train_images = train_images.transpose(0,3,1,2)\n",
    "val_images = val_images.transpose(0,3,1,2)\n",
    "test_images = test_images.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5525ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(360),\n",
    "    torchvision.transforms.RandomHorizontalFlip([0.5]),\n",
    "    torchvision.transforms.RandomVerticalFlip([0.5]),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1a22ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.Tensor(train_images)\n",
    "val_images = torch.Tensor(val_images)\n",
    "test_images = torch.Tensor(test_images)\n",
    "\n",
    "train_labels = torch.Tensor(train_labels).type(torch.LongTensor)\n",
    "val_labels = torch.Tensor(val_labels).type(torch.LongTensor)\n",
    "test_labels = torch.Tensor(test_labels).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "val_dataset = TensorDataset(val_images, val_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1510c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eaa1bb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffc993975e0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2,0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "103cb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "#model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "#model = torchvision.models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "\n",
    "model.fc = nn.Linear(2048, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "684be18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepShadows(nn.Module):\n",
    "    def __init__(self, num_classes: int = 2, dropout: float = 0.4) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            nn.Conv2d(16, 2*16, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            nn.Conv2d(2*16, 2*32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(40000, 1024),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "#model = DeepShadows()\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de298f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9618fc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.697252  [    0/ 2584]\n",
      "loss: 0.704585  [  640/ 2584]\n",
      "loss: 0.698383  [ 1280/ 2584]\n",
      "loss: 0.695381  [ 1920/ 2584]\n",
      "loss: 0.680360  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 0.698885 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.689856  [    0/ 2584]\n",
      "loss: 0.683732  [  640/ 2584]\n",
      "loss: 0.693164  [ 1280/ 2584]\n",
      "loss: 0.675554  [ 1920/ 2584]\n",
      "loss: 0.704734  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.699615 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.685596  [    0/ 2584]\n",
      "loss: 0.691337  [  640/ 2584]\n",
      "loss: 0.690271  [ 1280/ 2584]\n",
      "loss: 0.693353  [ 1920/ 2584]\n",
      "loss: 0.680752  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.698031 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.691447  [    0/ 2584]\n",
      "loss: 0.690150  [  640/ 2584]\n",
      "loss: 0.690706  [ 1280/ 2584]\n",
      "loss: 0.692445  [ 1920/ 2584]\n",
      "loss: 0.724070  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.696807 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.687562  [    0/ 2584]\n",
      "loss: 0.684117  [  640/ 2584]\n",
      "loss: 0.692758  [ 1280/ 2584]\n",
      "loss: 0.684458  [ 1920/ 2584]\n",
      "loss: 0.718522  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.691747 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.685005  [    0/ 2584]\n",
      "loss: 0.689625  [  640/ 2584]\n",
      "loss: 0.687715  [ 1280/ 2584]\n",
      "loss: 0.691426  [ 1920/ 2584]\n",
      "loss: 0.689605  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 0.693152 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.686463  [    0/ 2584]\n",
      "loss: 0.685886  [  640/ 2584]\n",
      "loss: 0.688041  [ 1280/ 2584]\n",
      "loss: 0.683238  [ 1920/ 2584]\n",
      "loss: 0.679658  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.693727 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.684588  [    0/ 2584]\n",
      "loss: 0.660309  [  640/ 2584]\n",
      "loss: 0.670235  [ 1280/ 2584]\n",
      "loss: 0.700001  [ 1920/ 2584]\n",
      "loss: 0.692352  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.692063 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.687651  [    0/ 2584]\n",
      "loss: 0.681855  [  640/ 2584]\n",
      "loss: 0.681968  [ 1280/ 2584]\n",
      "loss: 0.686305  [ 1920/ 2584]\n",
      "loss: 0.681014  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 0.689574 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.680412  [    0/ 2584]\n",
      "loss: 0.695778  [  640/ 2584]\n",
      "loss: 0.660300  [ 1280/ 2584]\n",
      "loss: 0.672220  [ 1920/ 2584]\n",
      "loss: 0.679596  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.692905 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.670474  [    0/ 2584]\n",
      "loss: 0.672306  [  640/ 2584]\n",
      "loss: 0.678365  [ 1280/ 2584]\n",
      "loss: 0.684349  [ 1920/ 2584]\n",
      "loss: 0.662083  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.688651 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.678439  [    0/ 2584]\n",
      "loss: 0.679026  [  640/ 2584]\n",
      "loss: 0.674022  [ 1280/ 2584]\n",
      "loss: 0.662952  [ 1920/ 2584]\n",
      "loss: 0.677792  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.685543 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.681272  [    0/ 2584]\n",
      "loss: 0.686736  [  640/ 2584]\n",
      "loss: 0.666872  [ 1280/ 2584]\n",
      "loss: 0.676996  [ 1920/ 2584]\n",
      "loss: 0.695486  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 55.8%, Avg loss: 0.685094 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.656612  [    0/ 2584]\n",
      "loss: 0.667352  [  640/ 2584]\n",
      "loss: 0.673679  [ 1280/ 2584]\n",
      "loss: 0.682742  [ 1920/ 2584]\n",
      "loss: 0.675378  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.680491 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.674298  [    0/ 2584]\n",
      "loss: 0.672654  [  640/ 2584]\n",
      "loss: 0.656788  [ 1280/ 2584]\n",
      "loss: 0.662167  [ 1920/ 2584]\n",
      "loss: 0.670498  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 0.680207 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.665829  [    0/ 2584]\n",
      "loss: 0.656592  [  640/ 2584]\n",
      "loss: 0.678213  [ 1280/ 2584]\n",
      "loss: 0.692888  [ 1920/ 2584]\n",
      "loss: 0.665443  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.675880 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.677960  [    0/ 2584]\n",
      "loss: 0.649163  [  640/ 2584]\n",
      "loss: 0.650842  [ 1280/ 2584]\n",
      "loss: 0.659275  [ 1920/ 2584]\n",
      "loss: 0.691765  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.674467 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.671351  [    0/ 2584]\n",
      "loss: 0.667172  [  640/ 2584]\n",
      "loss: 0.653735  [ 1280/ 2584]\n",
      "loss: 0.656950  [ 1920/ 2584]\n",
      "loss: 0.674356  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 0.678037 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.647524  [    0/ 2584]\n",
      "loss: 0.642566  [  640/ 2584]\n",
      "loss: 0.650834  [ 1280/ 2584]\n",
      "loss: 0.672071  [ 1920/ 2584]\n",
      "loss: 0.636143  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.674309 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.652252  [    0/ 2584]\n",
      "loss: 0.672289  [  640/ 2584]\n",
      "loss: 0.657505  [ 1280/ 2584]\n",
      "loss: 0.646315  [ 1920/ 2584]\n",
      "loss: 0.637903  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.673466 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.671085  [    0/ 2584]\n",
      "loss: 0.642975  [  640/ 2584]\n",
      "loss: 0.639709  [ 1280/ 2584]\n",
      "loss: 0.645099  [ 1920/ 2584]\n",
      "loss: 0.676578  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 0.669879 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.633277  [    0/ 2584]\n",
      "loss: 0.622743  [  640/ 2584]\n",
      "loss: 0.668685  [ 1280/ 2584]\n",
      "loss: 0.652326  [ 1920/ 2584]\n",
      "loss: 0.644871  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.664627 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.630895  [    0/ 2584]\n",
      "loss: 0.637543  [  640/ 2584]\n",
      "loss: 0.636726  [ 1280/ 2584]\n",
      "loss: 0.653109  [ 1920/ 2584]\n",
      "loss: 0.615780  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.662937 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.641429  [    0/ 2584]\n",
      "loss: 0.650753  [  640/ 2584]\n",
      "loss: 0.639413  [ 1280/ 2584]\n",
      "loss: 0.654173  [ 1920/ 2584]\n",
      "loss: 0.592575  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.654825 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.648821  [    0/ 2584]\n",
      "loss: 0.631584  [  640/ 2584]\n",
      "loss: 0.666258  [ 1280/ 2584]\n",
      "loss: 0.636286  [ 1920/ 2584]\n",
      "loss: 0.612878  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.656843 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.639476  [    0/ 2584]\n",
      "loss: 0.652212  [  640/ 2584]\n",
      "loss: 0.646701  [ 1280/ 2584]\n",
      "loss: 0.619500  [ 1920/ 2584]\n",
      "loss: 0.635473  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.653453 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.615727  [    0/ 2584]\n",
      "loss: 0.626131  [  640/ 2584]\n",
      "loss: 0.635211  [ 1280/ 2584]\n",
      "loss: 0.644896  [ 1920/ 2584]\n",
      "loss: 0.601849  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.652548 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.629105  [    0/ 2584]\n",
      "loss: 0.616307  [  640/ 2584]\n",
      "loss: 0.615124  [ 1280/ 2584]\n",
      "loss: 0.594424  [ 1920/ 2584]\n",
      "loss: 0.636295  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.639411 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.658008  [    0/ 2584]\n",
      "loss: 0.575034  [  640/ 2584]\n",
      "loss: 0.632972  [ 1280/ 2584]\n",
      "loss: 0.613638  [ 1920/ 2584]\n",
      "loss: 0.604638  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.635094 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.622775  [    0/ 2584]\n",
      "loss: 0.593508  [  640/ 2584]\n",
      "loss: 0.595275  [ 1280/ 2584]\n",
      "loss: 0.593304  [ 1920/ 2584]\n",
      "loss: 0.604169  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.638538 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.608342  [    0/ 2584]\n",
      "loss: 0.577417  [  640/ 2584]\n",
      "loss: 0.627746  [ 1280/ 2584]\n",
      "loss: 0.613505  [ 1920/ 2584]\n",
      "loss: 0.639272  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.628971 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.607587  [    0/ 2584]\n",
      "loss: 0.569601  [  640/ 2584]\n",
      "loss: 0.564819  [ 1280/ 2584]\n",
      "loss: 0.590464  [ 1920/ 2584]\n",
      "loss: 0.574633  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.625789 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.616887  [    0/ 2584]\n",
      "loss: 0.606517  [  640/ 2584]\n",
      "loss: 0.589018  [ 1280/ 2584]\n",
      "loss: 0.537163  [ 1920/ 2584]\n",
      "loss: 0.578164  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.619875 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.543687  [    0/ 2584]\n",
      "loss: 0.574942  [  640/ 2584]\n",
      "loss: 0.553907  [ 1280/ 2584]\n",
      "loss: 0.573731  [ 1920/ 2584]\n",
      "loss: 0.567853  [  960/ 2584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.606627 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.575284  [    0/ 2584]\n",
      "loss: 0.570584  [  640/ 2584]\n",
      "loss: 0.561178  [ 1280/ 2584]\n",
      "loss: 0.557766  [ 1920/ 2584]\n",
      "loss: 0.528282  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.596910 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.520489  [    0/ 2584]\n",
      "loss: 0.600718  [  640/ 2584]\n",
      "loss: 0.537588  [ 1280/ 2584]\n",
      "loss: 0.509462  [ 1920/ 2584]\n",
      "loss: 0.561245  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.591891 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.552483  [    0/ 2584]\n",
      "loss: 0.601168  [  640/ 2584]\n",
      "loss: 0.512535  [ 1280/ 2584]\n",
      "loss: 0.529530  [ 1920/ 2584]\n",
      "loss: 0.534055  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.599501 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.562311  [    0/ 2584]\n",
      "loss: 0.521051  [  640/ 2584]\n",
      "loss: 0.583523  [ 1280/ 2584]\n",
      "loss: 0.545339  [ 1920/ 2584]\n",
      "loss: 0.583481  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.582917 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.571879  [    0/ 2584]\n",
      "loss: 0.539687  [  640/ 2584]\n",
      "loss: 0.560229  [ 1280/ 2584]\n",
      "loss: 0.543685  [ 1920/ 2584]\n",
      "loss: 0.553497  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.571577 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.538787  [    0/ 2584]\n",
      "loss: 0.533257  [  640/ 2584]\n",
      "loss: 0.504894  [ 1280/ 2584]\n",
      "loss: 0.505192  [ 1920/ 2584]\n",
      "loss: 0.550409  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.575655 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.514448  [    0/ 2584]\n",
      "loss: 0.507471  [  640/ 2584]\n",
      "loss: 0.537431  [ 1280/ 2584]\n",
      "loss: 0.550194  [ 1920/ 2584]\n",
      "loss: 0.424171  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.565956 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.543008  [    0/ 2584]\n",
      "loss: 0.566292  [  640/ 2584]\n",
      "loss: 0.536199  [ 1280/ 2584]\n",
      "loss: 0.486727  [ 1920/ 2584]\n",
      "loss: 0.435269  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.563607 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.521621  [    0/ 2584]\n",
      "loss: 0.525384  [  640/ 2584]\n",
      "loss: 0.563261  [ 1280/ 2584]\n",
      "loss: 0.499267  [ 1920/ 2584]\n",
      "loss: 0.611070  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.544857 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.498120  [    0/ 2584]\n",
      "loss: 0.507105  [  640/ 2584]\n",
      "loss: 0.526298  [ 1280/ 2584]\n",
      "loss: 0.487839  [ 1920/ 2584]\n",
      "loss: 0.570236  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.543098 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.469680  [    0/ 2584]\n",
      "loss: 0.414771  [  640/ 2584]\n",
      "loss: 0.510520  [ 1280/ 2584]\n",
      "loss: 0.467120  [ 1920/ 2584]\n",
      "loss: 0.462647  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.553507 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.508739  [    0/ 2584]\n",
      "loss: 0.384252  [  640/ 2584]\n",
      "loss: 0.474375  [ 1280/ 2584]\n",
      "loss: 0.499216  [ 1920/ 2584]\n",
      "loss: 0.403982  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.518999 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.430597  [    0/ 2584]\n",
      "loss: 0.468046  [  640/ 2584]\n",
      "loss: 0.415885  [ 1280/ 2584]\n",
      "loss: 0.463768  [ 1920/ 2584]\n",
      "loss: 0.418619  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.523667 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.490733  [    0/ 2584]\n",
      "loss: 0.472860  [  640/ 2584]\n",
      "loss: 0.467530  [ 1280/ 2584]\n",
      "loss: 0.505874  [ 1920/ 2584]\n",
      "loss: 0.446763  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.506600 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.462579  [    0/ 2584]\n",
      "loss: 0.412226  [  640/ 2584]\n",
      "loss: 0.430566  [ 1280/ 2584]\n",
      "loss: 0.459963  [ 1920/ 2584]\n",
      "loss: 0.464722  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.510432 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.569146  [    0/ 2584]\n",
      "loss: 0.471717  [  640/ 2584]\n",
      "loss: 0.393644  [ 1280/ 2584]\n",
      "loss: 0.465408  [ 1920/ 2584]\n",
      "loss: 0.386328  [  960/ 2584]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.503563 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(50):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6f6b925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.475422 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/project/r/rbond/jorlo/ml-clusters/models/torch-wise/wise-resnet50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210d0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3076ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ba061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a3af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551728a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a690780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1e1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb4d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3037a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(nchan, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class test_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(test_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(nchan, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256, 64)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class cifar_test_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(cifar_test_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256, 64)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = test_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a5dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b85de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940c1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e4b6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.693437  [    0/ 4862]\n",
      "loss: 0.692682  [  640/ 4862]\n",
      "loss: 0.688887  [ 1280/ 4862]\n",
      "loss: 0.692684  [ 1920/ 4862]\n",
      "loss: 0.693431  [ 2560/ 4862]\n",
      "loss: 0.691977  [ 3200/ 4862]\n",
      "loss: 0.694814  [ 3840/ 4862]\n",
      "loss: 0.695524  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693517 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.690546  [    0/ 4862]\n",
      "loss: 0.694796  [  640/ 4862]\n",
      "loss: 0.691999  [ 1280/ 4862]\n",
      "loss: 0.694794  [ 1920/ 4862]\n",
      "loss: 0.694095  [ 2560/ 4862]\n",
      "loss: 0.696863  [ 3200/ 4862]\n",
      "loss: 0.693384  [ 3840/ 4862]\n",
      "loss: 0.691324  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693590 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.695430  [    0/ 4862]\n",
      "loss: 0.692708  [  640/ 4862]\n",
      "loss: 0.694021  [ 1280/ 4862]\n",
      "loss: 0.692061  [ 1920/ 4862]\n",
      "loss: 0.690791  [ 2560/ 4862]\n",
      "loss: 0.696526  [ 3200/ 4862]\n",
      "loss: 0.694622  [ 3840/ 4862]\n",
      "loss: 0.692715  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693266 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.695312  [    0/ 4862]\n",
      "loss: 0.692062  [  640/ 4862]\n",
      "loss: 0.695987  [ 1280/ 4862]\n",
      "loss: 0.691406  [ 1920/ 4862]\n",
      "loss: 0.696619  [ 2560/ 4862]\n",
      "loss: 0.694607  [ 3200/ 4862]\n",
      "loss: 0.692720  [ 3840/ 4862]\n",
      "loss: 0.695845  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693529 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.695816  [    0/ 4862]\n",
      "loss: 0.690271  [  640/ 4862]\n",
      "loss: 0.695149  [ 1280/ 4862]\n",
      "loss: 0.695730  [ 1920/ 4862]\n",
      "loss: 0.692731  [ 2560/ 4862]\n",
      "loss: 0.694524  [ 3200/ 4862]\n",
      "loss: 0.695109  [ 3840/ 4862]\n",
      "loss: 0.693329  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693236 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49479b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0])\n",
      "[1,    10] loss: 0.003\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
      "[1,    20] loss: 0.003\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "[1,    30] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1])\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
      "[1,    50] loss: 0.003\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "[1,    60] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0])\n",
      "[1,    70] loss: 0.003\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "947140da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693157 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(val_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddae3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab04d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fba999c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.202\n",
      "[1,  4000] loss: 1.839\n",
      "[1,  6000] loss: 1.657\n",
      "[1,  8000] loss: 1.554\n",
      "[1, 10000] loss: 1.480\n",
      "[1, 12000] loss: 1.389\n",
      "[2,  2000] loss: 1.306\n",
      "[2,  4000] loss: 1.257\n",
      "[2,  6000] loss: 1.223\n",
      "[2,  8000] loss: 1.173\n",
      "[2, 10000] loss: 1.148\n",
      "[2, 12000] loss: 1.107\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.060096  [    0/50000]\n",
      "loss: 0.890363  [  400/50000]\n",
      "loss: 0.372836  [  800/50000]\n",
      "loss: 1.821747  [ 1200/50000]\n",
      "loss: 0.707152  [ 1600/50000]\n",
      "loss: 0.345539  [ 2000/50000]\n",
      "loss: 0.877902  [ 2400/50000]\n",
      "loss: 1.524981  [ 2800/50000]\n",
      "loss: 2.065835  [ 3200/50000]\n",
      "loss: 0.595890  [ 3600/50000]\n",
      "loss: 1.007974  [ 4000/50000]\n",
      "loss: 1.117746  [ 4400/50000]\n",
      "loss: 0.597372  [ 4800/50000]\n",
      "loss: 0.854401  [ 5200/50000]\n",
      "loss: 1.041796  [ 5600/50000]\n",
      "loss: 1.052626  [ 6000/50000]\n",
      "loss: 1.214143  [ 6400/50000]\n",
      "loss: 1.106204  [ 6800/50000]\n",
      "loss: 0.805889  [ 7200/50000]\n",
      "loss: 0.478496  [ 7600/50000]\n",
      "loss: 0.453088  [ 8000/50000]\n",
      "loss: 0.777674  [ 8400/50000]\n",
      "loss: 0.684724  [ 8800/50000]\n",
      "loss: 1.556073  [ 9200/50000]\n",
      "loss: 0.855956  [ 9600/50000]\n",
      "loss: 1.304052  [10000/50000]\n",
      "loss: 0.975991  [10400/50000]\n",
      "loss: 1.312486  [10800/50000]\n",
      "loss: 0.939122  [11200/50000]\n",
      "loss: 1.570962  [11600/50000]\n",
      "loss: 1.059263  [12000/50000]\n",
      "loss: 0.603696  [12400/50000]\n",
      "loss: 1.262460  [12800/50000]\n",
      "loss: 0.899003  [13200/50000]\n",
      "loss: 0.516347  [13600/50000]\n",
      "loss: 1.412817  [14000/50000]\n",
      "loss: 1.940828  [14400/50000]\n",
      "loss: 1.421291  [14800/50000]\n",
      "loss: 1.527958  [15200/50000]\n",
      "loss: 0.660640  [15600/50000]\n",
      "loss: 2.087256  [16000/50000]\n",
      "loss: 1.992364  [16400/50000]\n",
      "loss: 0.742845  [16800/50000]\n",
      "loss: 0.919370  [17200/50000]\n",
      "loss: 2.403116  [17600/50000]\n",
      "loss: 0.861498  [18000/50000]\n",
      "loss: 0.633578  [18400/50000]\n",
      "loss: 0.306112  [18800/50000]\n",
      "loss: 0.616085  [19200/50000]\n",
      "loss: 1.428372  [19600/50000]\n",
      "loss: 1.214573  [20000/50000]\n",
      "loss: 0.237692  [20400/50000]\n",
      "loss: 0.888335  [20800/50000]\n",
      "loss: 1.127685  [21200/50000]\n",
      "loss: 1.894028  [21600/50000]\n",
      "loss: 1.653085  [22000/50000]\n",
      "loss: 0.887104  [22400/50000]\n",
      "loss: 0.768280  [22800/50000]\n",
      "loss: 1.276955  [23200/50000]\n",
      "loss: 0.724101  [23600/50000]\n",
      "loss: 1.389786  [24000/50000]\n",
      "loss: 1.412832  [24400/50000]\n",
      "loss: 0.697471  [24800/50000]\n",
      "loss: 1.534279  [25200/50000]\n",
      "loss: 0.221640  [25600/50000]\n",
      "loss: 0.670590  [26000/50000]\n",
      "loss: 2.082668  [26400/50000]\n",
      "loss: 0.617315  [26800/50000]\n",
      "loss: 0.219669  [27200/50000]\n",
      "loss: 1.576400  [27600/50000]\n",
      "loss: 0.521071  [28000/50000]\n",
      "loss: 0.667109  [28400/50000]\n",
      "loss: 0.446861  [28800/50000]\n",
      "loss: 1.891521  [29200/50000]\n",
      "loss: 0.504127  [29600/50000]\n",
      "loss: 0.900785  [30000/50000]\n",
      "loss: 1.059539  [30400/50000]\n",
      "loss: 1.090192  [30800/50000]\n",
      "loss: 0.438544  [31200/50000]\n",
      "loss: 0.929783  [31600/50000]\n",
      "loss: 1.704021  [32000/50000]\n",
      "loss: 1.206818  [32400/50000]\n",
      "loss: 0.657587  [32800/50000]\n",
      "loss: 0.345679  [33200/50000]\n",
      "loss: 1.015960  [33600/50000]\n",
      "loss: 1.343335  [34000/50000]\n",
      "loss: 0.347090  [34400/50000]\n",
      "loss: 0.932786  [34800/50000]\n",
      "loss: 0.758853  [35200/50000]\n",
      "loss: 0.915432  [35600/50000]\n",
      "loss: 0.995270  [36000/50000]\n",
      "loss: 0.204249  [36400/50000]\n",
      "loss: 0.415024  [36800/50000]\n",
      "loss: 0.493138  [37200/50000]\n",
      "loss: 0.420066  [37600/50000]\n",
      "loss: 1.280315  [38000/50000]\n",
      "loss: 0.264580  [38400/50000]\n",
      "loss: 1.276514  [38800/50000]\n",
      "loss: 1.482562  [39200/50000]\n",
      "loss: 0.770859  [39600/50000]\n",
      "loss: 2.079191  [40000/50000]\n",
      "loss: 1.281586  [40400/50000]\n",
      "loss: 0.515493  [40800/50000]\n",
      "loss: 0.845626  [41200/50000]\n",
      "loss: 0.738795  [41600/50000]\n",
      "loss: 0.445399  [42000/50000]\n",
      "loss: 1.413969  [42400/50000]\n",
      "loss: 1.336969  [42800/50000]\n",
      "loss: 0.504164  [43200/50000]\n",
      "loss: 0.654976  [43600/50000]\n",
      "loss: 0.782981  [44000/50000]\n",
      "loss: 0.397871  [44400/50000]\n",
      "loss: 1.796160  [44800/50000]\n",
      "loss: 1.590147  [45200/50000]\n",
      "loss: 0.364167  [45600/50000]\n",
      "loss: 0.896703  [46000/50000]\n",
      "loss: 1.035134  [46400/50000]\n",
      "loss: 0.276762  [46800/50000]\n",
      "loss: 0.595292  [47200/50000]\n",
      "loss: 0.572970  [47600/50000]\n",
      "loss: 0.073754  [48000/50000]\n",
      "loss: 0.448753  [48400/50000]\n",
      "loss: 0.465436  [48800/50000]\n",
      "loss: 0.205332  [49200/50000]\n",
      "loss: 1.312722  [49600/50000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.639621  [    0/50000]\n",
      "loss: 1.653802  [  400/50000]\n",
      "loss: 0.292712  [  800/50000]\n",
      "loss: 0.695848  [ 1200/50000]\n",
      "loss: 0.864940  [ 1600/50000]\n",
      "loss: 1.086525  [ 2000/50000]\n",
      "loss: 0.244835  [ 2400/50000]\n",
      "loss: 0.362542  [ 2800/50000]\n",
      "loss: 0.355307  [ 3200/50000]\n",
      "loss: 1.828213  [ 3600/50000]\n",
      "loss: 0.367143  [ 4000/50000]\n",
      "loss: 1.277882  [ 4400/50000]\n",
      "loss: 0.404677  [ 4800/50000]\n",
      "loss: 1.039233  [ 5200/50000]\n",
      "loss: 0.240120  [ 5600/50000]\n",
      "loss: 0.288508  [ 6000/50000]\n",
      "loss: 1.079822  [ 6400/50000]\n",
      "loss: 0.691280  [ 6800/50000]\n",
      "loss: 0.616539  [ 7200/50000]\n",
      "loss: 0.250594  [ 7600/50000]\n",
      "loss: 0.478822  [ 8000/50000]\n",
      "loss: 1.108712  [ 8400/50000]\n",
      "loss: 0.735408  [ 8800/50000]\n",
      "loss: 1.227458  [ 9200/50000]\n",
      "loss: 0.875349  [ 9600/50000]\n",
      "loss: 0.750414  [10000/50000]\n",
      "loss: 0.579952  [10400/50000]\n",
      "loss: 0.667180  [10800/50000]\n",
      "loss: 0.434435  [11200/50000]\n",
      "loss: 0.222996  [11600/50000]\n",
      "loss: 0.785771  [12000/50000]\n",
      "loss: 1.845934  [12400/50000]\n",
      "loss: 0.322084  [12800/50000]\n",
      "loss: 0.806117  [13200/50000]\n",
      "loss: 0.476806  [13600/50000]\n",
      "loss: 0.948234  [14000/50000]\n",
      "loss: 1.287097  [14400/50000]\n",
      "loss: 0.955032  [14800/50000]\n",
      "loss: 1.221172  [15200/50000]\n",
      "loss: 0.647941  [15600/50000]\n",
      "loss: 1.866461  [16000/50000]\n",
      "loss: 0.596470  [16400/50000]\n",
      "loss: 0.736356  [16800/50000]\n",
      "loss: 0.987067  [17200/50000]\n",
      "loss: 1.188918  [17600/50000]\n",
      "loss: 1.121629  [18000/50000]\n",
      "loss: 0.608543  [18400/50000]\n",
      "loss: 0.826440  [18800/50000]\n",
      "loss: 0.224803  [19200/50000]\n",
      "loss: 1.689422  [19600/50000]\n",
      "loss: 0.592396  [20000/50000]\n",
      "loss: 0.991186  [20400/50000]\n",
      "loss: 2.725237  [20800/50000]\n",
      "loss: 1.783676  [21200/50000]\n",
      "loss: 0.919037  [21600/50000]\n",
      "loss: 0.479510  [22000/50000]\n",
      "loss: 2.341299  [22400/50000]\n",
      "loss: 0.858123  [22800/50000]\n",
      "loss: 0.478736  [23200/50000]\n",
      "loss: 0.325498  [23600/50000]\n",
      "loss: 0.964267  [24000/50000]\n",
      "loss: 0.981799  [24400/50000]\n",
      "loss: 0.135917  [24800/50000]\n",
      "loss: 0.860336  [25200/50000]\n",
      "loss: 1.013093  [25600/50000]\n",
      "loss: 0.680560  [26000/50000]\n",
      "loss: 0.200244  [26400/50000]\n",
      "loss: 0.774907  [26800/50000]\n",
      "loss: 1.491934  [27200/50000]\n",
      "loss: 0.056649  [27600/50000]\n",
      "loss: 0.515200  [28000/50000]\n",
      "loss: 1.231576  [28400/50000]\n",
      "loss: 0.140577  [28800/50000]\n",
      "loss: 0.326717  [29200/50000]\n",
      "loss: 1.532465  [29600/50000]\n",
      "loss: 0.731401  [30000/50000]\n",
      "loss: 0.604404  [30400/50000]\n",
      "loss: 0.812461  [30800/50000]\n",
      "loss: 0.689520  [31200/50000]\n",
      "loss: 0.852476  [31600/50000]\n",
      "loss: 0.542539  [32000/50000]\n",
      "loss: 0.864933  [32400/50000]\n",
      "loss: 1.742018  [32800/50000]\n",
      "loss: 0.607229  [33200/50000]\n",
      "loss: 1.449111  [33600/50000]\n",
      "loss: 1.386970  [34000/50000]\n",
      "loss: 0.857375  [34400/50000]\n",
      "loss: 0.867152  [34800/50000]\n",
      "loss: 1.795165  [35200/50000]\n",
      "loss: 0.335545  [35600/50000]\n",
      "loss: 0.849488  [36000/50000]\n",
      "loss: 0.586552  [36400/50000]\n",
      "loss: 0.363186  [36800/50000]\n",
      "loss: 1.388242  [37200/50000]\n",
      "loss: 0.587786  [37600/50000]\n",
      "loss: 0.626836  [38000/50000]\n",
      "loss: 0.426292  [38400/50000]\n",
      "loss: 1.404154  [38800/50000]\n",
      "loss: 1.268189  [39200/50000]\n",
      "loss: 0.529208  [39600/50000]\n",
      "loss: 0.831767  [40000/50000]\n",
      "loss: 0.620528  [40400/50000]\n",
      "loss: 0.456411  [40800/50000]\n",
      "loss: 0.862475  [41200/50000]\n",
      "loss: 1.396451  [41600/50000]\n",
      "loss: 1.297489  [42000/50000]\n",
      "loss: 0.222226  [42400/50000]\n",
      "loss: 0.772526  [42800/50000]\n",
      "loss: 0.380015  [43200/50000]\n",
      "loss: 0.525589  [43600/50000]\n",
      "loss: 1.086556  [44000/50000]\n",
      "loss: 0.762763  [44400/50000]\n",
      "loss: 0.389924  [44800/50000]\n",
      "loss: 1.205146  [45200/50000]\n",
      "loss: 0.751991  [45600/50000]\n",
      "loss: 1.432924  [46000/50000]\n",
      "loss: 0.451831  [46400/50000]\n",
      "loss: 1.337262  [46800/50000]\n",
      "loss: 0.885977  [47200/50000]\n",
      "loss: 1.849783  [47600/50000]\n",
      "loss: 0.634227  [48000/50000]\n",
      "loss: 0.344398  [48400/50000]\n",
      "loss: 0.358285  [48800/50000]\n",
      "loss: 1.302626  [49200/50000]\n",
      "loss: 0.863636  [49600/50000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.202002  [    0/50000]\n",
      "loss: 0.995692  [  400/50000]\n",
      "loss: 0.054721  [  800/50000]\n",
      "loss: 1.228471  [ 1200/50000]\n",
      "loss: 0.690716  [ 1600/50000]\n",
      "loss: 0.924596  [ 2000/50000]\n",
      "loss: 0.739889  [ 2400/50000]\n",
      "loss: 0.347516  [ 2800/50000]\n",
      "loss: 1.594353  [ 3200/50000]\n",
      "loss: 0.499001  [ 3600/50000]\n",
      "loss: 0.414310  [ 4000/50000]\n",
      "loss: 1.066976  [ 4400/50000]\n",
      "loss: 0.894724  [ 4800/50000]\n",
      "loss: 0.425009  [ 5200/50000]\n",
      "loss: 0.261705  [ 5600/50000]\n",
      "loss: 1.619232  [ 6000/50000]\n",
      "loss: 0.685091  [ 6400/50000]\n",
      "loss: 0.631607  [ 6800/50000]\n",
      "loss: 1.542419  [ 7200/50000]\n",
      "loss: 0.853632  [ 7600/50000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.742525  [ 8000/50000]\n",
      "loss: 0.778277  [ 8400/50000]\n",
      "loss: 1.118055  [ 8800/50000]\n",
      "loss: 0.483934  [ 9200/50000]\n",
      "loss: 1.168017  [ 9600/50000]\n",
      "loss: 3.126446  [10000/50000]\n",
      "loss: 0.204966  [10400/50000]\n",
      "loss: 0.672307  [10800/50000]\n",
      "loss: 0.938400  [11200/50000]\n",
      "loss: 1.151416  [11600/50000]\n",
      "loss: 0.302296  [12000/50000]\n",
      "loss: 1.558384  [12400/50000]\n",
      "loss: 1.100916  [12800/50000]\n",
      "loss: 0.109435  [13200/50000]\n",
      "loss: 1.966909  [13600/50000]\n",
      "loss: 0.198178  [14000/50000]\n",
      "loss: 3.015626  [14400/50000]\n",
      "loss: 0.780849  [14800/50000]\n",
      "loss: 1.495462  [15200/50000]\n",
      "loss: 0.285534  [15600/50000]\n",
      "loss: 0.262317  [16000/50000]\n",
      "loss: 1.562996  [16400/50000]\n",
      "loss: 2.144889  [16800/50000]\n",
      "loss: 0.275759  [17200/50000]\n",
      "loss: 0.508386  [17600/50000]\n",
      "loss: 2.900773  [18000/50000]\n",
      "loss: 0.261640  [18400/50000]\n",
      "loss: 1.003810  [18800/50000]\n",
      "loss: 0.680074  [19200/50000]\n",
      "loss: 0.399111  [19600/50000]\n",
      "loss: 0.417976  [20000/50000]\n",
      "loss: 1.109479  [20400/50000]\n",
      "loss: 1.602119  [20800/50000]\n",
      "loss: 0.740902  [21200/50000]\n",
      "loss: 0.912175  [21600/50000]\n",
      "loss: 0.702477  [22000/50000]\n",
      "loss: 1.340326  [22400/50000]\n",
      "loss: 0.292778  [22800/50000]\n",
      "loss: 3.001721  [23200/50000]\n",
      "loss: 0.282721  [23600/50000]\n",
      "loss: 0.429418  [24000/50000]\n",
      "loss: 1.204721  [24400/50000]\n",
      "loss: 1.009758  [24800/50000]\n",
      "loss: 0.989984  [25200/50000]\n",
      "loss: 0.544792  [25600/50000]\n",
      "loss: 0.138613  [26000/50000]\n",
      "loss: 0.727053  [26400/50000]\n",
      "loss: 1.291738  [26800/50000]\n",
      "loss: 0.380883  [27200/50000]\n",
      "loss: 0.737675  [27600/50000]\n",
      "loss: 1.668164  [28000/50000]\n",
      "loss: 0.424108  [28400/50000]\n",
      "loss: 1.128641  [28800/50000]\n",
      "loss: 0.448262  [29200/50000]\n",
      "loss: 0.502998  [29600/50000]\n",
      "loss: 1.390533  [30000/50000]\n",
      "loss: 0.461268  [30400/50000]\n",
      "loss: 0.468525  [30800/50000]\n",
      "loss: 0.276306  [31200/50000]\n",
      "loss: 0.202937  [31600/50000]\n",
      "loss: 1.118357  [32000/50000]\n",
      "loss: 0.761776  [32400/50000]\n",
      "loss: 1.906657  [32800/50000]\n",
      "loss: 0.744753  [33200/50000]\n",
      "loss: 0.430453  [33600/50000]\n",
      "loss: 0.125181  [34000/50000]\n",
      "loss: 1.102085  [34400/50000]\n",
      "loss: 3.156640  [34800/50000]\n",
      "loss: 1.313067  [35200/50000]\n",
      "loss: 1.359367  [35600/50000]\n",
      "loss: 1.016252  [36000/50000]\n",
      "loss: 0.646700  [36400/50000]\n",
      "loss: 0.217673  [36800/50000]\n",
      "loss: 0.690380  [37200/50000]\n",
      "loss: 0.968114  [37600/50000]\n",
      "loss: 0.067531  [38000/50000]\n",
      "loss: 0.738000  [38400/50000]\n",
      "loss: 1.576040  [38800/50000]\n",
      "loss: 0.448933  [39200/50000]\n",
      "loss: 0.769586  [39600/50000]\n",
      "loss: 2.070192  [40000/50000]\n",
      "loss: 0.186902  [40400/50000]\n",
      "loss: 1.291891  [40800/50000]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "673b02cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532f348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1640fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbee108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5b887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca1a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54e5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3343235/3906010888.py:33: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=625, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of CNN/ConvNet Model\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        # Conv -> (?, 28, 28, 32)\n",
    "        # Pool -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        # Conv      ->(?, 14, 14, 64)\n",
    "        # Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        # Conv ->(?, 7, 7, 128)\n",
    "        # Pool ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#instantiate CNN model\n",
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d5944a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.333513  [    0/60000]\n",
      "loss: 2.310068  [ 6400/60000]\n",
      "loss: 2.273524  [12800/60000]\n",
      "loss: 2.255716  [19200/60000]\n",
      "loss: 2.244400  [25600/60000]\n",
      "loss: 2.212022  [32000/60000]\n",
      "loss: 2.213074  [38400/60000]\n",
      "loss: 2.173571  [44800/60000]\n",
      "loss: 2.146094  [51200/60000]\n",
      "loss: 2.090101  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.063510 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.088126  [    0/60000]\n",
      "loss: 2.029327  [ 6400/60000]\n",
      "loss: 1.865700  [12800/60000]\n",
      "loss: 1.799059  [19200/60000]\n",
      "loss: 1.561360  [25600/60000]\n",
      "loss: 1.439963  [32000/60000]\n",
      "loss: 1.300343  [38400/60000]\n",
      "loss: 1.148937  [44800/60000]\n",
      "loss: 1.130939  [51200/60000]\n",
      "loss: 1.039372  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.964817 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.035348  [    0/60000]\n",
      "loss: 1.024850  [ 6400/60000]\n",
      "loss: 0.736442  [12800/60000]\n",
      "loss: 0.960207  [19200/60000]\n",
      "loss: 0.845868  [25600/60000]\n",
      "loss: 0.868031  [32000/60000]\n",
      "loss: 0.871768  [38400/60000]\n",
      "loss: 0.744164  [44800/60000]\n",
      "loss: 0.841591  [51200/60000]\n",
      "loss: 0.886496  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.774923 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.766985  [    0/60000]\n",
      "loss: 0.864394  [ 6400/60000]\n",
      "loss: 0.576703  [12800/60000]\n",
      "loss: 0.865990  [19200/60000]\n",
      "loss: 0.773797  [25600/60000]\n",
      "loss: 0.791727  [32000/60000]\n",
      "loss: 0.804248  [38400/60000]\n",
      "loss: 0.685180  [44800/60000]\n",
      "loss: 0.774078  [51200/60000]\n",
      "loss: 0.833923  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.724752 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.676635  [    0/60000]\n",
      "loss: 0.793786  [ 6400/60000]\n",
      "loss: 0.523416  [12800/60000]\n",
      "loss: 0.812837  [19200/60000]\n",
      "loss: 0.729965  [25600/60000]\n",
      "loss: 0.759640  [32000/60000]\n",
      "loss: 0.761278  [38400/60000]\n",
      "loss: 0.654649  [44800/60000]\n",
      "loss: 0.741718  [51200/60000]\n",
      "loss: 0.792836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.693916 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.622157  [    0/60000]\n",
      "loss: 0.745662  [ 6400/60000]\n",
      "loss: 0.489755  [12800/60000]\n",
      "loss: 0.771136  [19200/60000]\n",
      "loss: 0.704861  [25600/60000]\n",
      "loss: 0.740639  [32000/60000]\n",
      "loss: 0.727107  [38400/60000]\n",
      "loss: 0.631473  [44800/60000]\n",
      "loss: 0.722566  [51200/60000]\n",
      "loss: 0.757392  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.669962 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.581996  [    0/60000]\n",
      "loss: 0.708483  [ 6400/60000]\n",
      "loss: 0.464897  [12800/60000]\n",
      "loss: 0.736457  [19200/60000]\n",
      "loss: 0.686697  [25600/60000]\n",
      "loss: 0.724395  [32000/60000]\n",
      "loss: 0.700341  [38400/60000]\n",
      "loss: 0.615090  [44800/60000]\n",
      "loss: 0.709408  [51200/60000]\n",
      "loss: 0.726727  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.649821 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.549971  [    0/60000]\n",
      "loss: 0.677273  [ 6400/60000]\n",
      "loss: 0.443762  [12800/60000]\n",
      "loss: 0.707362  [19200/60000]\n",
      "loss: 0.670232  [25600/60000]\n",
      "loss: 0.709434  [32000/60000]\n",
      "loss: 0.676416  [38400/60000]\n",
      "loss: 0.600556  [44800/60000]\n",
      "loss: 0.699560  [51200/60000]\n",
      "loss: 0.699143  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.631920 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.523097  [    0/60000]\n",
      "loss: 0.649075  [ 6400/60000]\n",
      "loss: 0.424766  [12800/60000]\n",
      "loss: 0.681190  [19200/60000]\n",
      "loss: 0.654910  [25600/60000]\n",
      "loss: 0.693513  [32000/60000]\n",
      "loss: 0.654135  [38400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e339e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cceed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0dfca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d08af891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "738cc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e5a77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35e2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        print(y)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d84af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
