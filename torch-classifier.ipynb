{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21ebf1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9966190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b82da8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERS\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "keep_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5965ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'freq'\n",
    "\n",
    "if data_type == 'freq':\n",
    "    data_dir = '/project/r/rbond/jorlo/datasets/act_freq_stamps/'\n",
    "\n",
    "    with np.load(data_dir + 'all_clusters.npz') as data:\n",
    "        pos_im = data['arr_0']\n",
    "    with np.load(data_dir + 'randoms.npz') as data:\n",
    "        neg_im = data['arr_0']    \n",
    "\n",
    "    nchan = 3\n",
    "        \n",
    "if data_type == 'ilc':\n",
    "\n",
    "    data_dir = '/project/r/rbond/jorlo/datasets/act_y_stamps/'\n",
    "\n",
    "    with np.load(data_dir + 'ilc_all_clusters.npz') as data:\n",
    "        pos_im = data['arr_0']\n",
    "    with np.load(data_dir + 'ilc_randoms.npz') as data:\n",
    "        neg_im = data['arr_0']  \n",
    "        \n",
    "    pos_im = np.expand_dims(pos_im, axis=-1)\n",
    "    neg_im = np.expand_dims(neg_im, axis=-1)\n",
    "    \n",
    "    nchan = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a25d2c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 41, 41, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fa6faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = min(pos_im.shape[0], neg_im.shape[0])\n",
    "train_size = int(0.7 * tot)\n",
    "val_size = int(0.15 * tot)\n",
    "test_size = int(0.15 * tot)\n",
    "\n",
    "train_pos = pos_im[:train_size]\n",
    "val_pos = pos_im[train_size:train_size + val_size]\n",
    "test_pos = pos_im[train_size + val_size:]\n",
    "\n",
    "train_neg = neg_im[:train_size]\n",
    "val_neg = neg_im[train_size:train_size + val_size]\n",
    "test_neg = neg_im[train_size + val_size:]\n",
    "\n",
    "input_shape = train_pos.shape[1:]\n",
    "\n",
    "train_images = np.concatenate((train_pos,train_neg))\n",
    "val_images = np.concatenate((val_pos,val_neg))\n",
    "test_images = np.concatenate((test_pos,test_neg))\n",
    "\n",
    "train_labels = np.array(train_pos.shape[0]*[int(1)] + train_neg.shape[0]*[int(0)])\n",
    "val_labels = np.array(val_pos.shape[0]*[int(1)] + val_neg.shape[0]*[int(0)])\n",
    "test_labels = np.array(test_pos.shape[0]*[int(1)] + test_neg.shape[0]*[int(0)])\n",
    "\n",
    "train_images = train_images.transpose(0,3,1,2)\n",
    "val_images = val_images.transpose(0,3,1,2)\n",
    "test_images = test_images.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "228a539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=360, width_shift_range=4,\n",
    "#height_shift_range=4,zoom_range=0.3)\n",
    "\n",
    "augment = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation(360),\n",
    "    torchvision.transforms.RandomHorizontalFlip([0.5]),\n",
    "    torchvision.transforms.RandomVerticalFlip([0.5]),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "673152a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.Tensor(train_images)\n",
    "val_images = torch.Tensor(val_images)\n",
    "test_images = torch.Tensor(test_images)\n",
    "\n",
    "train_labels = torch.Tensor(train_labels).type(torch.LongTensor)\n",
    "val_labels = torch.Tensor(val_labels).type(torch.LongTensor)\n",
    "test_labels = torch.Tensor(test_labels).type(torch.LongTensor)\n",
    "\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "val_dataset = TensorDataset(val_images, val_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39b4a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train = augment(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8b8c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataloader = DataLoader(augmented_train, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbcbf87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 41, 41])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6469b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b6b63e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffdac69c040>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2,0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "017bbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "#model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(512, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6b8eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb0d48a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.057707  [    0/ 5872]\n",
      "loss: 0.066508  [  640/ 5872]\n",
      "loss: 0.084073  [ 1280/ 5872]\n",
      "loss: 0.080279  [ 1920/ 5872]\n",
      "loss: 0.080676  [ 2560/ 5872]\n",
      "loss: 0.063138  [ 3200/ 5872]\n",
      "loss: 0.183514  [ 3840/ 5872]\n",
      "loss: 0.103876  [ 4480/ 5872]\n",
      "loss: 0.053278  [ 5120/ 5872]\n",
      "loss: 0.091826  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.133185 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.038230  [    0/ 5872]\n",
      "loss: 0.109347  [  640/ 5872]\n",
      "loss: 0.070491  [ 1280/ 5872]\n",
      "loss: 0.083281  [ 1920/ 5872]\n",
      "loss: 0.088843  [ 2560/ 5872]\n",
      "loss: 0.054765  [ 3200/ 5872]\n",
      "loss: 0.051837  [ 3840/ 5872]\n",
      "loss: 0.062978  [ 4480/ 5872]\n",
      "loss: 0.029957  [ 5120/ 5872]\n",
      "loss: 0.059714  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.129737 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.042186  [    0/ 5872]\n",
      "loss: 0.138051  [  640/ 5872]\n",
      "loss: 0.031712  [ 1280/ 5872]\n",
      "loss: 0.046288  [ 1920/ 5872]\n",
      "loss: 0.034464  [ 2560/ 5872]\n",
      "loss: 0.032745  [ 3200/ 5872]\n",
      "loss: 0.086028  [ 3840/ 5872]\n",
      "loss: 0.080636  [ 4480/ 5872]\n",
      "loss: 0.066579  [ 5120/ 5872]\n",
      "loss: 0.053856  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.131787 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.068848  [    0/ 5872]\n",
      "loss: 0.070006  [  640/ 5872]\n",
      "loss: 0.041606  [ 1280/ 5872]\n",
      "loss: 0.062202  [ 1920/ 5872]\n",
      "loss: 0.056049  [ 2560/ 5872]\n",
      "loss: 0.079208  [ 3200/ 5872]\n",
      "loss: 0.118333  [ 3840/ 5872]\n",
      "loss: 0.094228  [ 4480/ 5872]\n",
      "loss: 0.058495  [ 5120/ 5872]\n",
      "loss: 0.023809  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.121081 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.042731  [    0/ 5872]\n",
      "loss: 0.091528  [  640/ 5872]\n",
      "loss: 0.027906  [ 1280/ 5872]\n",
      "loss: 0.236608  [ 1920/ 5872]\n",
      "loss: 0.065549  [ 2560/ 5872]\n",
      "loss: 0.084450  [ 3200/ 5872]\n",
      "loss: 0.036705  [ 3840/ 5872]\n",
      "loss: 0.041810  [ 4480/ 5872]\n",
      "loss: 0.056252  [ 5120/ 5872]\n",
      "loss: 0.062160  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.113833 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.024781  [    0/ 5872]\n",
      "loss: 0.040884  [  640/ 5872]\n",
      "loss: 0.051059  [ 1280/ 5872]\n",
      "loss: 0.046113  [ 1920/ 5872]\n",
      "loss: 0.044854  [ 2560/ 5872]\n",
      "loss: 0.029986  [ 3200/ 5872]\n",
      "loss: 0.062894  [ 3840/ 5872]\n",
      "loss: 0.016818  [ 4480/ 5872]\n",
      "loss: 0.038038  [ 5120/ 5872]\n",
      "loss: 0.040240  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.109900 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.021792  [    0/ 5872]\n",
      "loss: 0.037878  [  640/ 5872]\n",
      "loss: 0.030568  [ 1280/ 5872]\n",
      "loss: 0.050090  [ 1920/ 5872]\n",
      "loss: 0.056584  [ 2560/ 5872]\n",
      "loss: 0.053089  [ 3200/ 5872]\n",
      "loss: 0.043464  [ 3840/ 5872]\n",
      "loss: 0.047380  [ 4480/ 5872]\n",
      "loss: 0.089117  [ 5120/ 5872]\n",
      "loss: 0.019334  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.117769 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.045736  [    0/ 5872]\n",
      "loss: 0.043951  [  640/ 5872]\n",
      "loss: 0.051168  [ 1280/ 5872]\n",
      "loss: 0.075954  [ 1920/ 5872]\n",
      "loss: 0.025954  [ 2560/ 5872]\n",
      "loss: 0.033307  [ 3200/ 5872]\n",
      "loss: 0.047151  [ 3840/ 5872]\n",
      "loss: 0.034000  [ 4480/ 5872]\n",
      "loss: 0.021815  [ 5120/ 5872]\n",
      "loss: 0.037637  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.119847 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.022073  [    0/ 5872]\n",
      "loss: 0.046346  [  640/ 5872]\n",
      "loss: 0.024939  [ 1280/ 5872]\n",
      "loss: 0.030299  [ 1920/ 5872]\n",
      "loss: 0.061867  [ 2560/ 5872]\n",
      "loss: 0.020441  [ 3200/ 5872]\n",
      "loss: 0.024850  [ 3840/ 5872]\n",
      "loss: 0.013482  [ 4480/ 5872]\n",
      "loss: 0.044771  [ 5120/ 5872]\n",
      "loss: 0.077582  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.105044 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.050733  [    0/ 5872]\n",
      "loss: 0.048824  [  640/ 5872]\n",
      "loss: 0.033188  [ 1280/ 5872]\n",
      "loss: 0.033109  [ 1920/ 5872]\n",
      "loss: 0.042146  [ 2560/ 5872]\n",
      "loss: 0.031988  [ 3200/ 5872]\n",
      "loss: 0.011560  [ 3840/ 5872]\n",
      "loss: 0.017356  [ 4480/ 5872]\n",
      "loss: 0.054489  [ 5120/ 5872]\n",
      "loss: 0.040116  [ 5760/ 5872]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.104844 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(augmented_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "177e509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.135855 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3037a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(nchan, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class test_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(test_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(nchan, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256, 64)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class cifar_test_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(cifar_test_Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(256, 64)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = test_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af56812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a5dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b85de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940c1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #print(y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            #print(pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e4b6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.693437  [    0/ 4862]\n",
      "loss: 0.692682  [  640/ 4862]\n",
      "loss: 0.688887  [ 1280/ 4862]\n",
      "loss: 0.692684  [ 1920/ 4862]\n",
      "loss: 0.693431  [ 2560/ 4862]\n",
      "loss: 0.691977  [ 3200/ 4862]\n",
      "loss: 0.694814  [ 3840/ 4862]\n",
      "loss: 0.695524  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693517 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.690546  [    0/ 4862]\n",
      "loss: 0.694796  [  640/ 4862]\n",
      "loss: 0.691999  [ 1280/ 4862]\n",
      "loss: 0.694794  [ 1920/ 4862]\n",
      "loss: 0.694095  [ 2560/ 4862]\n",
      "loss: 0.696863  [ 3200/ 4862]\n",
      "loss: 0.693384  [ 3840/ 4862]\n",
      "loss: 0.691324  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693590 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.695430  [    0/ 4862]\n",
      "loss: 0.692708  [  640/ 4862]\n",
      "loss: 0.694021  [ 1280/ 4862]\n",
      "loss: 0.692061  [ 1920/ 4862]\n",
      "loss: 0.690791  [ 2560/ 4862]\n",
      "loss: 0.696526  [ 3200/ 4862]\n",
      "loss: 0.694622  [ 3840/ 4862]\n",
      "loss: 0.692715  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693266 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.695312  [    0/ 4862]\n",
      "loss: 0.692062  [  640/ 4862]\n",
      "loss: 0.695987  [ 1280/ 4862]\n",
      "loss: 0.691406  [ 1920/ 4862]\n",
      "loss: 0.696619  [ 2560/ 4862]\n",
      "loss: 0.694607  [ 3200/ 4862]\n",
      "loss: 0.692720  [ 3840/ 4862]\n",
      "loss: 0.695845  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693529 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.695816  [    0/ 4862]\n",
      "loss: 0.690271  [  640/ 4862]\n",
      "loss: 0.695149  [ 1280/ 4862]\n",
      "loss: 0.695730  [ 1920/ 4862]\n",
      "loss: 0.692731  [ 2560/ 4862]\n",
      "loss: 0.694524  [ 3200/ 4862]\n",
      "loss: 0.695109  [ 3840/ 4862]\n",
      "loss: 0.693329  [ 4480/ 4862]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693236 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49479b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0])\n",
      "[1,    10] loss: 0.003\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
      "[1,    20] loss: 0.003\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "[1,    30] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1])\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
      "[1,    50] loss: 0.003\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "[1,    60] loss: 0.003\n",
      "tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0])\n",
      "[1,    70] loss: 0.003\n",
      "tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "947140da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693157 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(val_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddae3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab04d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fba999c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.202\n",
      "[1,  4000] loss: 1.839\n",
      "[1,  6000] loss: 1.657\n",
      "[1,  8000] loss: 1.554\n",
      "[1, 10000] loss: 1.480\n",
      "[1, 12000] loss: 1.389\n",
      "[2,  2000] loss: 1.306\n",
      "[2,  4000] loss: 1.257\n",
      "[2,  6000] loss: 1.223\n",
      "[2,  8000] loss: 1.173\n",
      "[2, 10000] loss: 1.148\n",
      "[2, 12000] loss: 1.107\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.060096  [    0/50000]\n",
      "loss: 0.890363  [  400/50000]\n",
      "loss: 0.372836  [  800/50000]\n",
      "loss: 1.821747  [ 1200/50000]\n",
      "loss: 0.707152  [ 1600/50000]\n",
      "loss: 0.345539  [ 2000/50000]\n",
      "loss: 0.877902  [ 2400/50000]\n",
      "loss: 1.524981  [ 2800/50000]\n",
      "loss: 2.065835  [ 3200/50000]\n",
      "loss: 0.595890  [ 3600/50000]\n",
      "loss: 1.007974  [ 4000/50000]\n",
      "loss: 1.117746  [ 4400/50000]\n",
      "loss: 0.597372  [ 4800/50000]\n",
      "loss: 0.854401  [ 5200/50000]\n",
      "loss: 1.041796  [ 5600/50000]\n",
      "loss: 1.052626  [ 6000/50000]\n",
      "loss: 1.214143  [ 6400/50000]\n",
      "loss: 1.106204  [ 6800/50000]\n",
      "loss: 0.805889  [ 7200/50000]\n",
      "loss: 0.478496  [ 7600/50000]\n",
      "loss: 0.453088  [ 8000/50000]\n",
      "loss: 0.777674  [ 8400/50000]\n",
      "loss: 0.684724  [ 8800/50000]\n",
      "loss: 1.556073  [ 9200/50000]\n",
      "loss: 0.855956  [ 9600/50000]\n",
      "loss: 1.304052  [10000/50000]\n",
      "loss: 0.975991  [10400/50000]\n",
      "loss: 1.312486  [10800/50000]\n",
      "loss: 0.939122  [11200/50000]\n",
      "loss: 1.570962  [11600/50000]\n",
      "loss: 1.059263  [12000/50000]\n",
      "loss: 0.603696  [12400/50000]\n",
      "loss: 1.262460  [12800/50000]\n",
      "loss: 0.899003  [13200/50000]\n",
      "loss: 0.516347  [13600/50000]\n",
      "loss: 1.412817  [14000/50000]\n",
      "loss: 1.940828  [14400/50000]\n",
      "loss: 1.421291  [14800/50000]\n",
      "loss: 1.527958  [15200/50000]\n",
      "loss: 0.660640  [15600/50000]\n",
      "loss: 2.087256  [16000/50000]\n",
      "loss: 1.992364  [16400/50000]\n",
      "loss: 0.742845  [16800/50000]\n",
      "loss: 0.919370  [17200/50000]\n",
      "loss: 2.403116  [17600/50000]\n",
      "loss: 0.861498  [18000/50000]\n",
      "loss: 0.633578  [18400/50000]\n",
      "loss: 0.306112  [18800/50000]\n",
      "loss: 0.616085  [19200/50000]\n",
      "loss: 1.428372  [19600/50000]\n",
      "loss: 1.214573  [20000/50000]\n",
      "loss: 0.237692  [20400/50000]\n",
      "loss: 0.888335  [20800/50000]\n",
      "loss: 1.127685  [21200/50000]\n",
      "loss: 1.894028  [21600/50000]\n",
      "loss: 1.653085  [22000/50000]\n",
      "loss: 0.887104  [22400/50000]\n",
      "loss: 0.768280  [22800/50000]\n",
      "loss: 1.276955  [23200/50000]\n",
      "loss: 0.724101  [23600/50000]\n",
      "loss: 1.389786  [24000/50000]\n",
      "loss: 1.412832  [24400/50000]\n",
      "loss: 0.697471  [24800/50000]\n",
      "loss: 1.534279  [25200/50000]\n",
      "loss: 0.221640  [25600/50000]\n",
      "loss: 0.670590  [26000/50000]\n",
      "loss: 2.082668  [26400/50000]\n",
      "loss: 0.617315  [26800/50000]\n",
      "loss: 0.219669  [27200/50000]\n",
      "loss: 1.576400  [27600/50000]\n",
      "loss: 0.521071  [28000/50000]\n",
      "loss: 0.667109  [28400/50000]\n",
      "loss: 0.446861  [28800/50000]\n",
      "loss: 1.891521  [29200/50000]\n",
      "loss: 0.504127  [29600/50000]\n",
      "loss: 0.900785  [30000/50000]\n",
      "loss: 1.059539  [30400/50000]\n",
      "loss: 1.090192  [30800/50000]\n",
      "loss: 0.438544  [31200/50000]\n",
      "loss: 0.929783  [31600/50000]\n",
      "loss: 1.704021  [32000/50000]\n",
      "loss: 1.206818  [32400/50000]\n",
      "loss: 0.657587  [32800/50000]\n",
      "loss: 0.345679  [33200/50000]\n",
      "loss: 1.015960  [33600/50000]\n",
      "loss: 1.343335  [34000/50000]\n",
      "loss: 0.347090  [34400/50000]\n",
      "loss: 0.932786  [34800/50000]\n",
      "loss: 0.758853  [35200/50000]\n",
      "loss: 0.915432  [35600/50000]\n",
      "loss: 0.995270  [36000/50000]\n",
      "loss: 0.204249  [36400/50000]\n",
      "loss: 0.415024  [36800/50000]\n",
      "loss: 0.493138  [37200/50000]\n",
      "loss: 0.420066  [37600/50000]\n",
      "loss: 1.280315  [38000/50000]\n",
      "loss: 0.264580  [38400/50000]\n",
      "loss: 1.276514  [38800/50000]\n",
      "loss: 1.482562  [39200/50000]\n",
      "loss: 0.770859  [39600/50000]\n",
      "loss: 2.079191  [40000/50000]\n",
      "loss: 1.281586  [40400/50000]\n",
      "loss: 0.515493  [40800/50000]\n",
      "loss: 0.845626  [41200/50000]\n",
      "loss: 0.738795  [41600/50000]\n",
      "loss: 0.445399  [42000/50000]\n",
      "loss: 1.413969  [42400/50000]\n",
      "loss: 1.336969  [42800/50000]\n",
      "loss: 0.504164  [43200/50000]\n",
      "loss: 0.654976  [43600/50000]\n",
      "loss: 0.782981  [44000/50000]\n",
      "loss: 0.397871  [44400/50000]\n",
      "loss: 1.796160  [44800/50000]\n",
      "loss: 1.590147  [45200/50000]\n",
      "loss: 0.364167  [45600/50000]\n",
      "loss: 0.896703  [46000/50000]\n",
      "loss: 1.035134  [46400/50000]\n",
      "loss: 0.276762  [46800/50000]\n",
      "loss: 0.595292  [47200/50000]\n",
      "loss: 0.572970  [47600/50000]\n",
      "loss: 0.073754  [48000/50000]\n",
      "loss: 0.448753  [48400/50000]\n",
      "loss: 0.465436  [48800/50000]\n",
      "loss: 0.205332  [49200/50000]\n",
      "loss: 1.312722  [49600/50000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.639621  [    0/50000]\n",
      "loss: 1.653802  [  400/50000]\n",
      "loss: 0.292712  [  800/50000]\n",
      "loss: 0.695848  [ 1200/50000]\n",
      "loss: 0.864940  [ 1600/50000]\n",
      "loss: 1.086525  [ 2000/50000]\n",
      "loss: 0.244835  [ 2400/50000]\n",
      "loss: 0.362542  [ 2800/50000]\n",
      "loss: 0.355307  [ 3200/50000]\n",
      "loss: 1.828213  [ 3600/50000]\n",
      "loss: 0.367143  [ 4000/50000]\n",
      "loss: 1.277882  [ 4400/50000]\n",
      "loss: 0.404677  [ 4800/50000]\n",
      "loss: 1.039233  [ 5200/50000]\n",
      "loss: 0.240120  [ 5600/50000]\n",
      "loss: 0.288508  [ 6000/50000]\n",
      "loss: 1.079822  [ 6400/50000]\n",
      "loss: 0.691280  [ 6800/50000]\n",
      "loss: 0.616539  [ 7200/50000]\n",
      "loss: 0.250594  [ 7600/50000]\n",
      "loss: 0.478822  [ 8000/50000]\n",
      "loss: 1.108712  [ 8400/50000]\n",
      "loss: 0.735408  [ 8800/50000]\n",
      "loss: 1.227458  [ 9200/50000]\n",
      "loss: 0.875349  [ 9600/50000]\n",
      "loss: 0.750414  [10000/50000]\n",
      "loss: 0.579952  [10400/50000]\n",
      "loss: 0.667180  [10800/50000]\n",
      "loss: 0.434435  [11200/50000]\n",
      "loss: 0.222996  [11600/50000]\n",
      "loss: 0.785771  [12000/50000]\n",
      "loss: 1.845934  [12400/50000]\n",
      "loss: 0.322084  [12800/50000]\n",
      "loss: 0.806117  [13200/50000]\n",
      "loss: 0.476806  [13600/50000]\n",
      "loss: 0.948234  [14000/50000]\n",
      "loss: 1.287097  [14400/50000]\n",
      "loss: 0.955032  [14800/50000]\n",
      "loss: 1.221172  [15200/50000]\n",
      "loss: 0.647941  [15600/50000]\n",
      "loss: 1.866461  [16000/50000]\n",
      "loss: 0.596470  [16400/50000]\n",
      "loss: 0.736356  [16800/50000]\n",
      "loss: 0.987067  [17200/50000]\n",
      "loss: 1.188918  [17600/50000]\n",
      "loss: 1.121629  [18000/50000]\n",
      "loss: 0.608543  [18400/50000]\n",
      "loss: 0.826440  [18800/50000]\n",
      "loss: 0.224803  [19200/50000]\n",
      "loss: 1.689422  [19600/50000]\n",
      "loss: 0.592396  [20000/50000]\n",
      "loss: 0.991186  [20400/50000]\n",
      "loss: 2.725237  [20800/50000]\n",
      "loss: 1.783676  [21200/50000]\n",
      "loss: 0.919037  [21600/50000]\n",
      "loss: 0.479510  [22000/50000]\n",
      "loss: 2.341299  [22400/50000]\n",
      "loss: 0.858123  [22800/50000]\n",
      "loss: 0.478736  [23200/50000]\n",
      "loss: 0.325498  [23600/50000]\n",
      "loss: 0.964267  [24000/50000]\n",
      "loss: 0.981799  [24400/50000]\n",
      "loss: 0.135917  [24800/50000]\n",
      "loss: 0.860336  [25200/50000]\n",
      "loss: 1.013093  [25600/50000]\n",
      "loss: 0.680560  [26000/50000]\n",
      "loss: 0.200244  [26400/50000]\n",
      "loss: 0.774907  [26800/50000]\n",
      "loss: 1.491934  [27200/50000]\n",
      "loss: 0.056649  [27600/50000]\n",
      "loss: 0.515200  [28000/50000]\n",
      "loss: 1.231576  [28400/50000]\n",
      "loss: 0.140577  [28800/50000]\n",
      "loss: 0.326717  [29200/50000]\n",
      "loss: 1.532465  [29600/50000]\n",
      "loss: 0.731401  [30000/50000]\n",
      "loss: 0.604404  [30400/50000]\n",
      "loss: 0.812461  [30800/50000]\n",
      "loss: 0.689520  [31200/50000]\n",
      "loss: 0.852476  [31600/50000]\n",
      "loss: 0.542539  [32000/50000]\n",
      "loss: 0.864933  [32400/50000]\n",
      "loss: 1.742018  [32800/50000]\n",
      "loss: 0.607229  [33200/50000]\n",
      "loss: 1.449111  [33600/50000]\n",
      "loss: 1.386970  [34000/50000]\n",
      "loss: 0.857375  [34400/50000]\n",
      "loss: 0.867152  [34800/50000]\n",
      "loss: 1.795165  [35200/50000]\n",
      "loss: 0.335545  [35600/50000]\n",
      "loss: 0.849488  [36000/50000]\n",
      "loss: 0.586552  [36400/50000]\n",
      "loss: 0.363186  [36800/50000]\n",
      "loss: 1.388242  [37200/50000]\n",
      "loss: 0.587786  [37600/50000]\n",
      "loss: 0.626836  [38000/50000]\n",
      "loss: 0.426292  [38400/50000]\n",
      "loss: 1.404154  [38800/50000]\n",
      "loss: 1.268189  [39200/50000]\n",
      "loss: 0.529208  [39600/50000]\n",
      "loss: 0.831767  [40000/50000]\n",
      "loss: 0.620528  [40400/50000]\n",
      "loss: 0.456411  [40800/50000]\n",
      "loss: 0.862475  [41200/50000]\n",
      "loss: 1.396451  [41600/50000]\n",
      "loss: 1.297489  [42000/50000]\n",
      "loss: 0.222226  [42400/50000]\n",
      "loss: 0.772526  [42800/50000]\n",
      "loss: 0.380015  [43200/50000]\n",
      "loss: 0.525589  [43600/50000]\n",
      "loss: 1.086556  [44000/50000]\n",
      "loss: 0.762763  [44400/50000]\n",
      "loss: 0.389924  [44800/50000]\n",
      "loss: 1.205146  [45200/50000]\n",
      "loss: 0.751991  [45600/50000]\n",
      "loss: 1.432924  [46000/50000]\n",
      "loss: 0.451831  [46400/50000]\n",
      "loss: 1.337262  [46800/50000]\n",
      "loss: 0.885977  [47200/50000]\n",
      "loss: 1.849783  [47600/50000]\n",
      "loss: 0.634227  [48000/50000]\n",
      "loss: 0.344398  [48400/50000]\n",
      "loss: 0.358285  [48800/50000]\n",
      "loss: 1.302626  [49200/50000]\n",
      "loss: 0.863636  [49600/50000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.202002  [    0/50000]\n",
      "loss: 0.995692  [  400/50000]\n",
      "loss: 0.054721  [  800/50000]\n",
      "loss: 1.228471  [ 1200/50000]\n",
      "loss: 0.690716  [ 1600/50000]\n",
      "loss: 0.924596  [ 2000/50000]\n",
      "loss: 0.739889  [ 2400/50000]\n",
      "loss: 0.347516  [ 2800/50000]\n",
      "loss: 1.594353  [ 3200/50000]\n",
      "loss: 0.499001  [ 3600/50000]\n",
      "loss: 0.414310  [ 4000/50000]\n",
      "loss: 1.066976  [ 4400/50000]\n",
      "loss: 0.894724  [ 4800/50000]\n",
      "loss: 0.425009  [ 5200/50000]\n",
      "loss: 0.261705  [ 5600/50000]\n",
      "loss: 1.619232  [ 6000/50000]\n",
      "loss: 0.685091  [ 6400/50000]\n",
      "loss: 0.631607  [ 6800/50000]\n",
      "loss: 1.542419  [ 7200/50000]\n",
      "loss: 0.853632  [ 7600/50000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.742525  [ 8000/50000]\n",
      "loss: 0.778277  [ 8400/50000]\n",
      "loss: 1.118055  [ 8800/50000]\n",
      "loss: 0.483934  [ 9200/50000]\n",
      "loss: 1.168017  [ 9600/50000]\n",
      "loss: 3.126446  [10000/50000]\n",
      "loss: 0.204966  [10400/50000]\n",
      "loss: 0.672307  [10800/50000]\n",
      "loss: 0.938400  [11200/50000]\n",
      "loss: 1.151416  [11600/50000]\n",
      "loss: 0.302296  [12000/50000]\n",
      "loss: 1.558384  [12400/50000]\n",
      "loss: 1.100916  [12800/50000]\n",
      "loss: 0.109435  [13200/50000]\n",
      "loss: 1.966909  [13600/50000]\n",
      "loss: 0.198178  [14000/50000]\n",
      "loss: 3.015626  [14400/50000]\n",
      "loss: 0.780849  [14800/50000]\n",
      "loss: 1.495462  [15200/50000]\n",
      "loss: 0.285534  [15600/50000]\n",
      "loss: 0.262317  [16000/50000]\n",
      "loss: 1.562996  [16400/50000]\n",
      "loss: 2.144889  [16800/50000]\n",
      "loss: 0.275759  [17200/50000]\n",
      "loss: 0.508386  [17600/50000]\n",
      "loss: 2.900773  [18000/50000]\n",
      "loss: 0.261640  [18400/50000]\n",
      "loss: 1.003810  [18800/50000]\n",
      "loss: 0.680074  [19200/50000]\n",
      "loss: 0.399111  [19600/50000]\n",
      "loss: 0.417976  [20000/50000]\n",
      "loss: 1.109479  [20400/50000]\n",
      "loss: 1.602119  [20800/50000]\n",
      "loss: 0.740902  [21200/50000]\n",
      "loss: 0.912175  [21600/50000]\n",
      "loss: 0.702477  [22000/50000]\n",
      "loss: 1.340326  [22400/50000]\n",
      "loss: 0.292778  [22800/50000]\n",
      "loss: 3.001721  [23200/50000]\n",
      "loss: 0.282721  [23600/50000]\n",
      "loss: 0.429418  [24000/50000]\n",
      "loss: 1.204721  [24400/50000]\n",
      "loss: 1.009758  [24800/50000]\n",
      "loss: 0.989984  [25200/50000]\n",
      "loss: 0.544792  [25600/50000]\n",
      "loss: 0.138613  [26000/50000]\n",
      "loss: 0.727053  [26400/50000]\n",
      "loss: 1.291738  [26800/50000]\n",
      "loss: 0.380883  [27200/50000]\n",
      "loss: 0.737675  [27600/50000]\n",
      "loss: 1.668164  [28000/50000]\n",
      "loss: 0.424108  [28400/50000]\n",
      "loss: 1.128641  [28800/50000]\n",
      "loss: 0.448262  [29200/50000]\n",
      "loss: 0.502998  [29600/50000]\n",
      "loss: 1.390533  [30000/50000]\n",
      "loss: 0.461268  [30400/50000]\n",
      "loss: 0.468525  [30800/50000]\n",
      "loss: 0.276306  [31200/50000]\n",
      "loss: 0.202937  [31600/50000]\n",
      "loss: 1.118357  [32000/50000]\n",
      "loss: 0.761776  [32400/50000]\n",
      "loss: 1.906657  [32800/50000]\n",
      "loss: 0.744753  [33200/50000]\n",
      "loss: 0.430453  [33600/50000]\n",
      "loss: 0.125181  [34000/50000]\n",
      "loss: 1.102085  [34400/50000]\n",
      "loss: 3.156640  [34800/50000]\n",
      "loss: 1.313067  [35200/50000]\n",
      "loss: 1.359367  [35600/50000]\n",
      "loss: 1.016252  [36000/50000]\n",
      "loss: 0.646700  [36400/50000]\n",
      "loss: 0.217673  [36800/50000]\n",
      "loss: 0.690380  [37200/50000]\n",
      "loss: 0.968114  [37600/50000]\n",
      "loss: 0.067531  [38000/50000]\n",
      "loss: 0.738000  [38400/50000]\n",
      "loss: 1.576040  [38800/50000]\n",
      "loss: 0.448933  [39200/50000]\n",
      "loss: 0.769586  [39600/50000]\n",
      "loss: 2.070192  [40000/50000]\n",
      "loss: 0.186902  [40400/50000]\n",
      "loss: 1.291891  [40800/50000]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b02cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532f348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1640fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbee108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5b887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca1a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54e5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3343235/3906010888.py:33: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=625, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation of CNN/ConvNet Model\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        # Conv -> (?, 28, 28, 32)\n",
    "        # Pool -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        # Conv      ->(?, 14, 14, 64)\n",
    "        # Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        # Conv ->(?, 7, 7, 128)\n",
    "        # Pool ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "#instantiate CNN model\n",
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d5944a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.333513  [    0/60000]\n",
      "loss: 2.310068  [ 6400/60000]\n",
      "loss: 2.273524  [12800/60000]\n",
      "loss: 2.255716  [19200/60000]\n",
      "loss: 2.244400  [25600/60000]\n",
      "loss: 2.212022  [32000/60000]\n",
      "loss: 2.213074  [38400/60000]\n",
      "loss: 2.173571  [44800/60000]\n",
      "loss: 2.146094  [51200/60000]\n",
      "loss: 2.090101  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.063510 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.088126  [    0/60000]\n",
      "loss: 2.029327  [ 6400/60000]\n",
      "loss: 1.865700  [12800/60000]\n",
      "loss: 1.799059  [19200/60000]\n",
      "loss: 1.561360  [25600/60000]\n",
      "loss: 1.439963  [32000/60000]\n",
      "loss: 1.300343  [38400/60000]\n",
      "loss: 1.148937  [44800/60000]\n",
      "loss: 1.130939  [51200/60000]\n",
      "loss: 1.039372  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.964817 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.035348  [    0/60000]\n",
      "loss: 1.024850  [ 6400/60000]\n",
      "loss: 0.736442  [12800/60000]\n",
      "loss: 0.960207  [19200/60000]\n",
      "loss: 0.845868  [25600/60000]\n",
      "loss: 0.868031  [32000/60000]\n",
      "loss: 0.871768  [38400/60000]\n",
      "loss: 0.744164  [44800/60000]\n",
      "loss: 0.841591  [51200/60000]\n",
      "loss: 0.886496  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.774923 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.766985  [    0/60000]\n",
      "loss: 0.864394  [ 6400/60000]\n",
      "loss: 0.576703  [12800/60000]\n",
      "loss: 0.865990  [19200/60000]\n",
      "loss: 0.773797  [25600/60000]\n",
      "loss: 0.791727  [32000/60000]\n",
      "loss: 0.804248  [38400/60000]\n",
      "loss: 0.685180  [44800/60000]\n",
      "loss: 0.774078  [51200/60000]\n",
      "loss: 0.833923  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.724752 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.676635  [    0/60000]\n",
      "loss: 0.793786  [ 6400/60000]\n",
      "loss: 0.523416  [12800/60000]\n",
      "loss: 0.812837  [19200/60000]\n",
      "loss: 0.729965  [25600/60000]\n",
      "loss: 0.759640  [32000/60000]\n",
      "loss: 0.761278  [38400/60000]\n",
      "loss: 0.654649  [44800/60000]\n",
      "loss: 0.741718  [51200/60000]\n",
      "loss: 0.792836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.693916 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.622157  [    0/60000]\n",
      "loss: 0.745662  [ 6400/60000]\n",
      "loss: 0.489755  [12800/60000]\n",
      "loss: 0.771136  [19200/60000]\n",
      "loss: 0.704861  [25600/60000]\n",
      "loss: 0.740639  [32000/60000]\n",
      "loss: 0.727107  [38400/60000]\n",
      "loss: 0.631473  [44800/60000]\n",
      "loss: 0.722566  [51200/60000]\n",
      "loss: 0.757392  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.669962 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.581996  [    0/60000]\n",
      "loss: 0.708483  [ 6400/60000]\n",
      "loss: 0.464897  [12800/60000]\n",
      "loss: 0.736457  [19200/60000]\n",
      "loss: 0.686697  [25600/60000]\n",
      "loss: 0.724395  [32000/60000]\n",
      "loss: 0.700341  [38400/60000]\n",
      "loss: 0.615090  [44800/60000]\n",
      "loss: 0.709408  [51200/60000]\n",
      "loss: 0.726727  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.649821 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.549971  [    0/60000]\n",
      "loss: 0.677273  [ 6400/60000]\n",
      "loss: 0.443762  [12800/60000]\n",
      "loss: 0.707362  [19200/60000]\n",
      "loss: 0.670232  [25600/60000]\n",
      "loss: 0.709434  [32000/60000]\n",
      "loss: 0.676416  [38400/60000]\n",
      "loss: 0.600556  [44800/60000]\n",
      "loss: 0.699560  [51200/60000]\n",
      "loss: 0.699143  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.631920 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.523097  [    0/60000]\n",
      "loss: 0.649075  [ 6400/60000]\n",
      "loss: 0.424766  [12800/60000]\n",
      "loss: 0.681190  [19200/60000]\n",
      "loss: 0.654910  [25600/60000]\n",
      "loss: 0.693513  [32000/60000]\n",
      "loss: 0.654135  [38400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e339e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cceed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0dfca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d08af891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "738cc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e5a77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35e2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        print(y)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d84af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-torch",
   "language": "python",
   "name": "ml-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
